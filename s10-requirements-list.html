<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>S10. Full SHALL/SHOULD Requirements ‚Äî TFL Guide</title>
  <link rel="stylesheet" href="assets/style.css">
  <style>
    .req-type-section { margin-bottom:22px; }
    .clause-col { width:90px;font-family:monospace;font-size:0.8em;color:#555;white-space:nowrap;vertical-align:top;padding-top:5px; }
    .req-text { font-size:0.87em;line-height:1.55; }
    .source-note { background:#fff3cd;border:1px solid #ffc107;border-left:4px solid #e6a817;border-radius:6px;padding:12px 16px;margin-bottom:20px;font-size:0.87em; }
  </style>
</head>
<body>
<div class="layout">
  <nav class="sidebar">
    <div class="sidebar-header">
      <div class="logo">ISO/IEC 42117-X</div>
      <div class="title">TFL Ïö¥ÏòÅ Í∞ÄÏù¥Îìú</div>
      <div class="version">v1.0 ¬∑ 2026-02-20</div>
    </div>
    <div class="sidebar-nav">
      <div class="nav-section">
        <div class="nav-label">Î©îÏù∏</div>
        <a href="index.html" class="nav-item">üìã Í∞ÄÏù¥Îìú Ìôà</a>
      </div>
      <div class="nav-section">
        <div class="nav-label">ÏÑπÏÖò</div>
        <a href="s01-overview.html" class="nav-item"><span class="section-id">S01</span>TFL Í∞úÏöî Î∞è ÌëúÏ§Ä Ï≤¥Í≥Ñ</a>
        <a href="s02-characteristics.html" class="nav-item"><span class="section-id">S02</span>28Í∞ú TCM Ïã†Î¢∞ÏÑ± ÌäπÏÑ±</a>
        <a href="s03-claims.html" class="nav-item"><span class="section-id">S03</span>Simple Claim Ïπ¥ÌÉàÎ°úÍ∑∏</a>
        <a href="s04-tc-mapping.html" class="nav-item"><span class="section-id">S04</span>TCM-TC ÏöîÍµ¨ÏÇ¨Ìï≠ Îß§Ìïë</a>
        <a href="s05-ca-guide.html" class="nav-item"><span class="section-id">S05</span>CA Ïù¥Ìñâ Í∞ÄÏù¥Îìú</a>
        <a href="s06-gaps.html" class="nav-item"><span class="section-id">S06</span>Ïª§Î≤ÑÎ¶¨ÏßÄ Í∞≠ Î∞è Í∂åÍ≥†ÏÇ¨Ìï≠</a>
        <a href="s07-references.html" class="nav-item"><span class="section-id">S07</span>Ï∞∏Ï°∞ ÌëúÏ§Ä Î∞è Ïö©Ïñ¥ ÏÇ¨Ï†Ñ</a>
        <a href="s08-standards-diagram.html" class="nav-item"><span class="section-id">S08</span>ÌëúÏ§Ä Ïó∞Í¥ÄÎèÑ</a>
        <a href="s09-vocabulary.html" class="nav-item"><span class="section-id">S09</span>ÌäπÏÑ± Vocabulary ÎπÑÍµê</a>
        <a href="s10-requirements-list.html" class="nav-item active"><span class="section-id">S10</span>ÏöîÍµ¨ÏÇ¨Ìï≠ Ï†ÑÏ≤¥ Î™©Î°ù</a>
        <a href="s11-tc-claim-mapping.html" class="nav-item"><span class="section-id">S11</span>TC-Claim Îß§Ìïë Ìëú</a>
        <a href="s12-standards-tracker.html" class="nav-item"><span class="section-id">S12</span>ÌëúÏ§Ä Î∞úÌñâ ÌòÑÌô© Ï∂îÏ†ÅÍ∏∞</a>
        <a href="s13-dtc-card.html" class="nav-item"><span class="section-id">S13</span>AI Developer Technical Card</a>
        <a href="s14-atfs-qfd.html" class="nav-item"><span class="section-id">S14</span>ATFS / QFD (Type III)</a>
      </div>
    </div>
  </nav>

  <div style="flex:1;display:flex;flex-direction:column;min-width:0">
    <div class="page-header">
      <div>
        <h1>S10 ‚Äî Full SHALL/SHOULD Requirements List</h1>
        <div class="breadcrumb"><a href="index.html">Ìôà</a> ‚Ä∫ S10</div>
      </div>
    </div>

    <div class="main-content">

      <div class="source-note">
        <strong>Data Integrity Note:</strong> All statements are extracted <strong>verbatim</strong> from normative content only. Excluded sections:
        <strong>Foreword</strong>, <strong>Bibliography</strong>, <strong>Clause 3 (Terms &amp; Definitions)</strong>,
        <strong>EXAMPLE blocks</strong>, and sentences that are <strong>purely citing external document clauses</strong>
        (e.g., "ISO/IEC XXXX:YYYY, X.X shall apply").
        No AI-paraphrased content included.
      </div>

      <div class="content-section">
        <h2>Overview</h2>
        <div class="stats-grid">
          <div class="stat-card"><div class="num">23</div><div class="label">Source Documents</div></div>
          <div class="stat-card green"><div class="num">225</div><div class="label">SHALL Statements</div></div>
          <div class="stat-card orange"><div class="num">756</div><div class="label">SHOULD Statements</div></div>
          <div class="stat-card"><div class="num">981</div><div class="label">Total Statements</div></div>
        </div>
      </div>

      <div class="content-section">
        <h2>Document Requirements</h2>
        <div class="filter-bar" style="margin-bottom:16px">
          <span class="filter-label">Filter:</span>
          <span class="filter-btn active" onclick="filterDocs('all',this)">All Documents</span>
          <span class="filter-btn" onclick="filterDocs('has-shall',this)">Has SHALL</span>
          <span class="filter-btn" onclick="filterDocs('has-should',this)">Has SHOULD</span>
          <span class="filter-btn" onclick="expandAll()">Expand All</span>
          <span class="filter-btn" onclick="collapseAll()">Collapse All</span>
        </div>

  <div class="req-accordion" id="acc-TC-DOC-01" data-shall="0" data-should="131">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-01')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">01</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC DTS 25058</span>
        <span class="badge badge-dts">DTS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">AI System Quality Evaluation Guidance</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 131</span>
        <span id="arrow-TC-DOC-01" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-01" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Accountability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Bias/Fairness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Controllability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Efficiency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Functional Correctness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Effectiveness ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Quality ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Usability ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Integrity ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Authenticity ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Privacy ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Risk ‚¨Ü</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (131)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5</td>
              <td class="req-text">The guidance in this document should complement the SQuaRE quality evaluation process described in</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">Quality of the functional completeness sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.2.1.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Quality of the functional correctness sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.2.2.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Functional correctness should be evaluated with the proper key performance indicators (KPIs) and measurements.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Measurements and key performance indicators should be established to measure the capability of an AI system to do a specific task and to evaluate the amount of unpredictability of the system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">The right evaluation measurements should be used to measure functional correctness based on an AI system&#x27;s problem type and the stakeholders&#x27; objectives. For a list of typical evaluation measurements, refer to ISO/IEC 23053:2022, 6.5.5.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Functional correctness should also be evaluated using functional testing methods, such as;</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Functional correctness evaluation techniques should be performed on different and representative datasets.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">The best machine learning (ML) model should be selected using the appropriate evaluation measurements against a validation dataset. The simple ML model validation technique uses only one validation dataset. However, a K-fold cross-validation technique is suggested when possible.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">In a separate back-testing phase, the selected ML model should be tested once again with new data (the testing dataset) for consistency.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Training, validation and testing datasets should all be built with different data. Validation and testing datasets should all be built with representative subsets of the actual operation conditions.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Validation and testing datasets should all be built with representative subsets of the actual operation conditions.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">The ML model should be tested against datasets with known cohorts to identify positive or negative bias creep.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">The final settings to tune the ML model (e.g. the cut-off threshold in classification) should be defined together with the business users.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">The functional correctness should be evaluated on production data for monitoring purposes. Product deployment should take place after the back-testing phase.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Product deployment should take place after the back-testing phase.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">The quality of the functional appropriateness sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.2.3.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">An AI system should have a mechanism to adapt dynamically to changes in the production data, by using one of the following;</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">The organization should develop an adaptation system to generate a feedback loop. This managed system comprises four essential functions: monitor; analyse; plan; execute.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">Functional adaptability should be evaluated using measurements, key performance indicators and functional testing methods, as documented in 6.2, to measure the adaptability of an AI system to a new dataset.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">The organization should take into consideration resource trade-offs when selecting the best ML model for deployment, as the most accurate ML model can be prohibitively expensive to computationally evaluate. Refer to 7.2 for more details.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">Quality of the time behaviour sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.3.1.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The organization should calculate time behaviour during the training, evaluation and inference workflows under normal conditions as part of normal workflows in production, using the production environment, infrastructures and computing resources, as time behaviour depends on resource utilization. Refer to 7.2 for guidance on resource utilization.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The organization should consider an AI system adaptability mechanism while measuring the process duration. For example, a system that consists of a sequence of retraining, evaluation and inference should measure the duration of the entire sequence of workflows.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">should measure the duration of the entire sequence of workflows. The organization should test and assess potential conflicts between computational resources. For example, if the training and inference workflows use the same computational resources or if multiple inferences happen simultaneously, this can negatively affect time behaviour of an AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The organization should test and assess potential conflicts between computational resources. For example, if the training and inference workflows use the same computational resources or if multiple inferences happen simultaneously, this can negatively affect time behaviour of an AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The organization should test and assess timing between data collection, data transformation and other data-dependent AI system workflows. For example, AI system inference cannot be processed if the required input data are not collected and transformed beforehand.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">Quality of the resource utilization sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.3.2.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">The organization should allocate the appropriate resources during the training process of a ML-based AI system. Factors such as computational resource types, time requirements, data quantity, ML model type and the quantity of hyperparameters can impact the resources required to complete this process.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">An AI system can also get its input from other AI systems, which should be considered as this can create additional dependencies on utilized resources.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">The organization should consider available resources through a system adaptability strategy (e.g. incremental learning, active learning, online learning or retraining strategy). For example, an adaptability strategy consisting of retraining an AI system hourly takes few resources during inference but several resources during the retraining. Consider as part of this adaptability strategy that inference and retraining can happen simultaneously.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">Quality of the capacity sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">8.1</td>
              <td class="req-text">Quality of the co-existence sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.4.1.</td>
            </tr>
            <tr>
              <td class="clause-col">8.2</td>
              <td class="req-text">Quality of the interoperability sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.4.2.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">Quality of the learnability sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.5.1.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">Quality of the usability sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">9.3</td>
              <td class="req-text">Quality of the operability sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">9.4</td>
              <td class="req-text">Quality of the user error protection sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.5.4.</td>
            </tr>
            <tr>
              <td class="clause-col">9.5</td>
              <td class="req-text">Quality of the user interface aesthetics sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.5.5.</td>
            </tr>
            <tr>
              <td class="clause-col">9.6</td>
              <td class="req-text">Quality of the accessibility sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.5.6.</td>
            </tr>
            <tr>
              <td class="clause-col">9.7</td>
              <td class="req-text">The organization should use the controllability framework according to ISO/IEC TS 8200 for an AI system designed to be controllable. For an evaluation, the following should be considered and prepared in advance:</td>
            </tr>
            <tr>
              <td class="clause-col">9.7</td>
              <td class="req-text">system designed to be controllable. For an evaluation, the following should be considered and prepared in advance:</td>
            </tr>
            <tr>
              <td class="clause-col">9.7</td>
              <td class="req-text">The evaluation of an AI system&#x27;s controllability should include the following:</td>
            </tr>
            <tr>
              <td class="clause-col">9.7</td>
              <td class="req-text">control functionalities, as well as their useful combinations or workflows, should be tested.</td>
            </tr>
            <tr>
              <td class="clause-col">9.7</td>
              <td class="req-text">where the system is designed, implemented or required to be in should be tested. A specific set of test items should be prepared according to the evaluation objectives.</td>
            </tr>
            <tr>
              <td class="clause-col">9.7</td>
              <td class="req-text">A specific set of test items should be prepared according to the evaluation objectives. Sub-processes of control, such as control transfer, engagement and disengagement of control and uncertainty handling of control transfer, as well as the actual control, should be tested. For each control functionality, the test item can check the following. Stakeholders can apply a subset of these according to specific concerns:</td>
            </tr>
            <tr>
              <td class="clause-col">9.7</td>
              <td class="req-text">uncertainty handling of control transfer, as well as the actual control, should be tested. For each control functionality, the test item can check the following. Stakeholders can apply a subset of these according to specific concerns:</td>
            </tr>
            <tr>
              <td class="clause-col">9.7</td>
              <td class="req-text">and engagement of control) should be checked for an AI system that operates in risky environments.</td>
            </tr>
            <tr>
              <td class="clause-col">9.7</td>
              <td class="req-text">should carry out, such that the entire control functionality process can complete and return results. All operations needed by all sub-processes count.</td>
            </tr>
            <tr>
              <td class="clause-col">9.8</td>
              <td class="req-text">The presentation of information to stakeholders should be open, comprehensive and understandable. The organization should be able to understand, trace and document all privacy-relevant data processing considerations, including the legal, technical and organizational.</td>
            </tr>
            <tr>
              <td class="clause-col">9.8</td>
              <td class="req-text">The organization should be able to understand, trace and document all privacy-relevant data processing considerations, including the legal, technical and organizational.</td>
            </tr>
            <tr>
              <td class="clause-col">9.8</td>
              <td class="req-text">An AI system should have clear owners who are accountable for meeting the expected benefits and communicating about the system&#x27;s outcomes to the stakeholders.</td>
            </tr>
            <tr>
              <td class="clause-col">9.8</td>
              <td class="req-text">The relevant characteristics used in an AI system should be comprehensive, accessible, clear and understandable to the stakeholders. For example, considering that only a finite number of variables are used as input to an AI system, this limitation should be communicated clearly to avoid misunderstandings.</td>
            </tr>
            <tr>
              <td class="clause-col">9.8</td>
              <td class="req-text">variables are used as input to an AI system, this limitation should be communicated clearly to avoid misunderstandings.</td>
            </tr>
            <tr>
              <td class="clause-col">9.8</td>
              <td class="req-text">The organization should communicate the risks of an AI system&#x27;s output (i.e. predictions, decisions or activities) affecting society, the economy or the environment in a clear, accurate, timely, honest and complete manner.</td>
            </tr>
            <tr>
              <td class="clause-col">9.8</td>
              <td class="req-text">The organization should communicate an AI system&#x27;s output (i.e. predictions, decisions or activities) to relevant stakeholders in a comprehensive, accessible and understandable manner.</td>
            </tr>
            <tr>
              <td class="clause-col">9.8</td>
              <td class="req-text">Appropriate information about an AI system and its level of quality should be made available to relevant stakeholders.</td>
            </tr>
            <tr>
              <td class="clause-col">10.1</td>
              <td class="req-text">Quality of the maturity sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">10.2</td>
              <td class="req-text">Quality of the availability sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">Quality of the fault tolerance sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.6.3.</td>
            </tr>
            <tr>
              <td class="clause-col">10.4</td>
              <td class="req-text">Quality of the recoverability sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.6.4.</td>
            </tr>
            <tr>
              <td class="clause-col">10.5</td>
              <td class="req-text">The robustness of an AI system should be measured under normal operational conditions. These conditions are dependent on the AI system&#x27;s domain, as described in ISO/IEC 24029-2:2023, 5.2. The bounded domain should:</td>
            </tr>
            <tr>
              <td class="clause-col">10.5</td>
              <td class="req-text">bounded domain should:</td>
            </tr>
            <tr>
              <td class="clause-col">10.5</td>
              <td class="req-text">The following actions should be considered to measure the AI system&#x27;s robustness against the bounded domain:</td>
            </tr>
            <tr>
              <td class="clause-col">10.5</td>
              <td class="req-text">An AI system should endure long-tail, black swan and abnormal events. The following actions should be considered:</td>
            </tr>
            <tr>
              <td class="clause-col">10.5</td>
              <td class="req-text">An AI system should handle diverse perceptible and unforeseen attacks. The following actions should be considered:</td>
            </tr>
            <tr>
              <td class="clause-col">10.5</td>
              <td class="req-text">An AI system should generate representative outputs under abnormal environmental conditions by:</td>
            </tr>
            <tr>
              <td class="clause-col">10.5</td>
              <td class="req-text">or if a backup workflow should be triggered;</td>
            </tr>
            <tr>
              <td class="clause-col">10.5</td>
              <td class="req-text">‚Äî implementing a robust backup workflow that should be operational when an AI system fails to generate outputs.</td>
            </tr>
            <tr>
              <td class="clause-col">10.5</td>
              <td class="req-text">An AI system&#x27;s hardware should be robust to common causes of failure. From the point of view of common cause failures at the hardware level, there are no differences between conventional and AI- based hardware. A list of relevant common cause failures can be found in International Standards such as IEC 61508-2 and ISO 26262-11.</td>
            </tr>
            <tr>
              <td class="clause-col">10.5</td>
              <td class="req-text">An AI system should adapt to evolving environments. Refer to 6.4 for the recommended guidance on functional adaptability.</td>
            </tr>
            <tr>
              <td class="clause-col">11.1</td>
              <td class="req-text">Quality of the confidentiality sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.7.1.</td>
            </tr>
            <tr>
              <td class="clause-col">11.1</td>
              <td class="req-text">The organization should evaluate an AI system&#x27;s processes for ensuring data (both for input and output data) privacy or confidentiality to assess if they can be reverse engineered and would compromise identity protection or data integrity.</td>
            </tr>
            <tr>
              <td class="clause-col">11.1</td>
              <td class="req-text">The organization should establish a mitigation plan, including depersonalization, synthetic data, dimension reduction or other mechanisms if a confidentiality risk is established.</td>
            </tr>
            <tr>
              <td class="clause-col">11.2</td>
              <td class="req-text">Quality of the integrity sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">11.2</td>
              <td class="req-text">The organization should evaluate an AI system to assess if the system&#x27;s integrity can be corrupted by erroneous or adversarial (data poisoning) input data.</td>
            </tr>
            <tr>
              <td class="clause-col">11.2</td>
              <td class="req-text">The organization should establish a mitigation plan, including fraud detection, anomaly detection or other mechanisms if an integrity risk is identified.</td>
            </tr>
            <tr>
              <td class="clause-col">11.3</td>
              <td class="req-text">Quality of the non-repudiation sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.7.3.</td>
            </tr>
            <tr>
              <td class="clause-col">11.4</td>
              <td class="req-text">Quality of the accountability sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.7.4.</td>
            </tr>
            <tr>
              <td class="clause-col">11.5</td>
              <td class="req-text">Quality of the authenticity sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.7.5.</td>
            </tr>
            <tr>
              <td class="clause-col">12.1</td>
              <td class="req-text">Quality of the modularity sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.8.1.</td>
            </tr>
            <tr>
              <td class="clause-col">12.2</td>
              <td class="req-text">Quality of the reusability sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">12.2</td>
              <td class="req-text">The organization should store and abstract knowledge for an ML-based AI system during system creation for future use according to ISO/IEC 23053:2022, 7.7. An AI system consists of an input, weighting and output component. An AI system embeds knowledge in its learned weights, but the meaning of those weights requires contextualization by both the input and output components. Knowledge is accessed through the output components.</td>
            </tr>
            <tr>
              <td class="clause-col">12.2</td>
              <td class="req-text">A reusable AI system should be designed to avoid the consequences of using embedded system weights in conceptual domains the training data does not cover. It also requires a pipeline able to differentiate</td>
            </tr>
            <tr>
              <td class="clause-col">12.2</td>
              <td class="req-text">An AI system should not be used for purposes it was not designed for, without taking additional steps for allowing system flexibility. This can involve additional feature engineering, retraining and revalidation to adapt the system to the new domain. A reusable AI system should be designed in a way to allow flexibility in how it interprets new information with limited manual tuning from designers.</td>
            </tr>
            <tr>
              <td class="clause-col">12.2</td>
              <td class="req-text">revalidation to adapt the system to the new domain. A reusable AI system should be designed in a way to allow flexibility in how it interprets new information with limited manual tuning from designers.</td>
            </tr>
            <tr>
              <td class="clause-col">12.2</td>
              <td class="req-text">Validation that an AI system is reusable for another concept should include considerations of the functional correctness guidance and measurements. Refer to 6.2 for guidance on functional correctness.</td>
            </tr>
            <tr>
              <td class="clause-col">12.3</td>
              <td class="req-text">Quality of the analysability sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.8.3.</td>
            </tr>
            <tr>
              <td class="clause-col">12.3</td>
              <td class="req-text">The organization should implement a mechanism for the logging of an AI system&#x27;s predictions and explanations.</td>
            </tr>
            <tr>
              <td class="clause-col">12.4</td>
              <td class="req-text">Quality of the modifiability sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.8.4.</td>
            </tr>
            <tr>
              <td class="clause-col">12.4</td>
              <td class="req-text">The organization should design an AI system adaptability mechanism in a way that ensures proper adaptation of the ML model without introducing defects. The development team should ensure that every new version of the ML model or system is increasing or at least maintaining its level of quality.</td>
            </tr>
            <tr>
              <td class="clause-col">12.4</td>
              <td class="req-text">adaptation of the ML model without introducing defects. The development team should ensure that every new version of the ML model or system is increasing or at least maintaining its level of quality.</td>
            </tr>
            <tr>
              <td class="clause-col">12.4</td>
              <td class="req-text">Conditional workflows should be established if normal retraining is degrading the system quality. Refer to 6.4 for guidance on functional adaptability.</td>
            </tr>
            <tr>
              <td class="clause-col">12.5</td>
              <td class="req-text">Quality of the testability sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">12.5</td>
              <td class="req-text">The organization should implement a complete and efficient testing strategy with every new update to the system to avoid introducing defects.</td>
            </tr>
            <tr>
              <td class="clause-col">12.5</td>
              <td class="req-text">The organization should implement complete, proactive and continuous monitoring capabilities.</td>
            </tr>
            <tr>
              <td class="clause-col">13.1</td>
              <td class="req-text">Quality of the adaptability sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.9.1.</td>
            </tr>
            <tr>
              <td class="clause-col">13.2</td>
              <td class="req-text">Quality of the installability sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.9.2.</td>
            </tr>
            <tr>
              <td class="clause-col">13.3</td>
              <td class="req-text">Quality of the replaceability sub-characteristic should be measured against quality measures according to ISO/IEC 25023:2016, 8.9.3.</td>
            </tr>
            <tr>
              <td class="clause-col">14</td>
              <td class="req-text">Quality of the effectiveness sub-characteristic should be measured against quality measures according to ISO/IEC 25022:2016, 8.2.</td>
            </tr>
            <tr>
              <td class="clause-col">15</td>
              <td class="req-text">Quality of the efficiency sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">16.1</td>
              <td class="req-text">Quality of the satisfaction sub-characteristic should be measured against quality measures according to ISO/IEC 25022:2016, 8.4.1.</td>
            </tr>
            <tr>
              <td class="clause-col">16.2</td>
              <td class="req-text">Quality of the usefulness sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">16.3</td>
              <td class="req-text">Quality of the trust sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">16.4</td>
              <td class="req-text">Quality of the pleasure sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">16.5</td>
              <td class="req-text">Quality of the comfort sub-characteristic should be measured against quality measures according to</td>
            </tr>
            <tr>
              <td class="clause-col">17.1</td>
              <td class="req-text">AI risks should be identified, quantified or qualitatively described and prioritized against risk criteria and objectives relevant to the organization, according to a risk management framework for AI systems.</td>
            </tr>
            <tr>
              <td class="clause-col">17.1</td>
              <td class="req-text">Risks arising from the development, the use of AI systems and their management should be managed according to ISO/IEC 23894.</td>
            </tr>
            <tr>
              <td class="clause-col">17.2</td>
              <td class="req-text">Quality of the economic risk mitigation sub-characteristic should be measured against quality measures according to ISO/IEC 25022:2016, 8.5.2.</td>
            </tr>
            <tr>
              <td class="clause-col">17.3</td>
              <td class="req-text">The organization should measure the quality of the health and safety risk mitigation sub-characteristic against quality measures according to ISO/IEC 25022:2016, 8.5.3.</td>
            </tr>
            <tr>
              <td class="clause-col">17.3</td>
              <td class="req-text">Achieving health and safety risk mitigation should be an ongoing activity across the total product life cycle of a system, including early concept, requirements engineering, design, development, quality management, supply, acquisition, maintenance and decommissioning (ISO/IEC 22989). The requirements phase is especially important in designing safer AI systems.[18],[21] Other standards and methods address health and safety in different ways and can complement the requirements and guidance provided in this document.</td>
            </tr>
            <tr>
              <td class="clause-col">17.3</td>
              <td class="req-text">Consequently, AI system designers and users should carefully consider the relative importance of their chosen quality characteristics.</td>
            </tr>
            <tr>
              <td class="clause-col">17.3</td>
              <td class="req-text">To effectively mitigate safety risks, an organization should:</td>
            </tr>
            <tr>
              <td class="clause-col">17.3</td>
              <td class="req-text">An organization should prevent the following situations:</td>
            </tr>
            <tr>
              <td class="clause-col">17.3</td>
              <td class="req-text">Hazards should be designed out of:</td>
            </tr>
            <tr>
              <td class="clause-col">17.4</td>
              <td class="req-text">Quality of the environmental risk mitigation sub-characteristic should be measured against quality measures according to ISO/IEC 25022:2016, 8.5.4.</td>
            </tr>
            <tr>
              <td class="clause-col">17.4</td>
              <td class="req-text">An organization should identify potential direct and indirect harms and benefits related to an AI system regarding environmental considerations, such as energy consumption, greenhouse gas emissions or water consumption, as described in Reference [27]. In addition to the typical environmental risks considered for a computer system, an AI development team should address the following elements:</td>
            </tr>
            <tr>
              <td class="clause-col">17.4</td>
              <td class="req-text">considered for a computer system, an AI development team should address the following elements:</td>
            </tr>
            <tr>
              <td class="clause-col">17.4</td>
              <td class="req-text">computer resources utilized during training, inference and functional adaptability should be assessed, since the more resources, and the longer these resources are utilized, the more negative environmental impacts are caused by an AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">17.4</td>
              <td class="req-text">The risk assessment and mitigation plan should also address indirect risks, such as the following:</td>
            </tr>
            <tr>
              <td class="clause-col">17.4</td>
              <td class="req-text">types of AI system). An organization should consider the environmental risks across their entire supply chain.</td>
            </tr>
            <tr>
              <td class="clause-col">17.4</td>
              <td class="req-text">The identified risks should be further studied to the extent that mitigation actions can become part of the system requirements.</td>
            </tr>
            <tr>
              <td class="clause-col">17.5</td>
              <td class="req-text">An organization that develops, produces, deploys or uses AI systems should manage societal and ethical risks by using ISO/IEC 23894, which provides guidance on key societal or ethical considerations.</td>
            </tr>
            <tr>
              <td class="clause-col">17.5</td>
              <td class="req-text">An organization should identify and address societal concerns and ethical considerations throughout the life cycle of AI systems as part of a risk mitigation process. Please refer to ISO/IEC TR 24368,</td>
            </tr>
            <tr>
              <td class="clause-col">18.1</td>
              <td class="req-text">Since the performance of an AI system changes throughout its life cycle, the development team should continuously measure its context coverage.</td>
            </tr>
            <tr>
              <td class="clause-col">18.2</td>
              <td class="req-text">Quality of the context completeness sub-characteristic should be measured against quality measures according to ISO/IEC 25022:2016, 8.6.2.</td>
            </tr>
            <tr>
              <td class="clause-col">18.2</td>
              <td class="req-text">During an AI system quality assessment, the organization should consider significant life cycle factors of either one or a combination of circumstances, opportunities and individual preferences.</td>
            </tr>
            <tr>
              <td class="clause-col">18.2</td>
              <td class="req-text">characteristics of significant factors, the cross-correlation features of these factors should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">18.2</td>
              <td class="req-text">statistical characteristics of these factors should define the quality of context of use description. The description of the context of use can be used for generating test datasets for assessment of AI system characteristics. In this case, the quality of the description of the context of use determines the representativeness of the measured characteristics of an AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">0</td>
              <td class="req-text">The context coverage, context completeness and flexibility should all be linked by the following formula: C D C D C =</td>
            </tr>
            <tr>
              <td class="clause-col">18.3</td>
              <td class="req-text">Quality of the flexibility sub-characteristic should be measured against quality measures according to</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (9)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Reliability-001</code></td><td>Reliability</td><td>Level 2</td><td style="font-size:0.85em">[System] achieves reliability score ‚â• [X]% measured by [metric] over [period] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Reliability-003</code></td><td>Reliability</td><td>Level 3</td><td style="font-size:0.85em">[System] demonstrates mean output deviation &lt; [threshold] under [condition] with statistical significance p &lt; [value] pe‚Ä¶</td></tr>
          <tr><td><code>SC-Transparency-003</code></td><td>Transparency</td><td>Level 3</td><td style="font-size:0.85em">[System] provides real-time explainability logging with audit trail per [standard] verified by [party]‚Ä¶</td></tr>
          <tr><td><code>SC-Functional_Correctness-001</code></td><td>Functional Correctness</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves [metric] ‚â• [X]% on [benchmark] with acceptance criteria documented per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Functional_Correctness-002</code></td><td>Functional Correctness</td><td>Level 2</td><td style="font-size:0.85em">[System] satisfies functional correctness KPIs: [metric1] ‚â• [X], [metric2] ‚â• [Y] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Efficiency-001</code></td><td>Efficiency</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves inference latency ‚â§ [X]ms (p99) with resource utilization ‚â§ [Y]% per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Efficiency-002</code></td><td>Efficiency</td><td>Level 2</td><td style="font-size:0.85em">[System] meets efficiency requirements: throughput ‚â• [X] req/s with compute cost ‚â§ [Y] per inference per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Availability-001</code></td><td>Availability</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves availability ‚â• [X]% (SLA) with MTTR ‚â§ [Y] hours per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Resilience-002</code></td><td>Resilience</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves recovery time ‚â§ [X] seconds from [failure type] with data integrity maintained per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-02" data-shall="2" data-should="1">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-02')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">02</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC 25059</span>
        <span class="badge badge-is">IS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Quality Model for AI Systems</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 2</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 1</span>
        <span id="arrow-TC-DOC-02" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-02" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Accountability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Availability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Bias/Fairness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Controllability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Efficiency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Functional Correctness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Intervenability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Resilience</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Security</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Quality ‚¨Ü</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (2)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">this clause. The unmodified original characteristics are part of the AI system product model and shall be interpreted in accordance with ISO/IEC 25010.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">characteristics are part of the quality in use model and shall be interpreted as defined in ISO/IEC 25010.</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (1)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">These themes should be considered along with the information in ISO/IEC TR 24368, with regard to the desirable characteristics of systems in order to mitigate societal and ethical risk.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (2)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Reliability-001</code></td><td>Reliability</td><td>Level 2</td><td style="font-size:0.85em">[System] achieves reliability score ‚â• [X]% measured by [metric] over [period] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Transparency-002</code></td><td>Transparency</td><td>Level 2</td><td style="font-size:0.85em">[System] achieves Transparency Level [N] as defined in [standard] with [N] of [M] criteria satisfied‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-03" data-shall="6" data-should="7">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-03')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">03</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC TS 42119-2</span>
        <span class="badge badge-ts">TS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">AI System Testing</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 6</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 7</span>
        <span id="arrow-TC-DOC-03" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-03" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Accountability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Bias/Fairness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Efficiency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Explainability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Functional Correctness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Security</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Privacy ‚¨Ü</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (6)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">The testing of AI systems and their components shall be performed in accordance with ISO/IEC/IEEE 29119-2.</td>
            </tr>
            <tr>
              <td class="clause-col">5.6</td>
              <td class="req-text">The documentation of the testing of AI systems and their components shall be produced in accordance with ISO/IEC/IEEE 29119-3.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">For risks that can be partially or fully addressed through software testing, appropriate means of treating identified risks shall be determined (based on the level of risk exposure and categorization).</td>
            </tr>
            <tr>
              <td class="clause-col">7.3.4.3</td>
              <td class="req-text">For ML models, all test data shall be completely independent of the training data.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3.4.3</td>
              <td class="req-text">The test cases shall be executed by the model and the results shall be recorded.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3.4.3</td>
              <td class="req-text">The test results shall be used to determine whether the model has passed or failed the testing by comparing the combined results of the executed test cases with the specified acceptance criteria.</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (7)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.7</td>
              <td class="req-text">When using this document and the ISO/IEC/IEEE 29119 series in the context of AI systems, relevant stakeholders should be identified and documented. This defined group of stakeholders should be used consistently in all test processes.</td>
            </tr>
            <tr>
              <td class="clause-col">6</td>
              <td class="req-text">In practice, the relevant architecture and development techniques for the specific system under test should be used for this process.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3.3.2</td>
              <td class="req-text">Data privacy and protection, trade secrets and intellectual property rights should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3.3.7.4</td>
              <td class="req-text">For instance, a risk-based approach identifies that it is especially important that the model should respond correctly when an age attribute is set to a value of &#x27;minor&#x27;.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3.3.9</td>
              <td class="req-text">Where data augmentation has been used to increase the size of the training dataset, the review should check that this has not disproportionately increased the number of samples that can lead to a biased ML model.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3.4.6</td>
              <td class="req-text">There is a concerted effort to improve both internal and external documentation by agreeing on the information that should be recorded and provided about each AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4.4.2.5</td>
              <td class="req-text">For value change coverage, a value between 0 and 1 should be chosen as the change amount.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-04" data-shall="41" data-should="83">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-04')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">04</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC 5338</span>
        <span class="badge badge-is">IS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">AI System Life Cycle Processes</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 41</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 83</span>
        <span id="arrow-TC-DOC-04" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-04" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Accountability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Bias/Fairness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Controllability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Explainability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Functional Correctness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Resilience</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Security</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Privacy ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Risk ‚¨Ü</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (41)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">absence of that process, activity or task shall be justified and documented. The requirements in ISO/IEC/IEEE 15288:2023, 4.2 and 4.3, and ISO/IEC/IEEE 12207:2017, 4.2 and 4.3 shall also apply.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">ISO/IEC/IEEE 15288:2023, 4.2 and 4.3, and ISO/IEC/IEEE 12207:2017, 4.2 and 4.3 shall also apply.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.1.1 shall apply. 6.1.1.3 AI-specific particularities The acquisition process described in ISO/IEC/IEEE 15288 and ISO/IEC/IEEE 12207 should be extended beyond the acquisition of products or services to include the possible acquisition of data for the AI data engineering process (see 6.4.8). This new kind of acquisition activity can introduce new acquisition</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.1.2 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.2.1 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.2.2 shall apply. 6.2.3 Portfolio management process 6.2.3.1 Purpose The purpose of the portfolio management process is to initiate and sustain necessary, sufficient and</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.2.3 shall apply. 6.2.3.3 AI-specific particularities There are no additional activities or tasks defined in the portfolio management process. When implementing the activities and tasks in 6.2.3.2, organizations should consider the following AI-specific particularities:</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.2.4 shall apply. 6.2.4.3 AI-specific particularities There are no additional activities or tasks defined in the human resource management process.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.2.5 shall apply. 6.2.5.3 AI-specific particularities There are no additional activities or tasks defined in the quality management process. When implementing the activities and tasks in 6.2.5.2, organizations should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.2.6 shall apply. 6.2.6.3 AI-specific particularities There are no additional activities or tasks defined in the knowledge management process. When implementing the activities and tasks in 6.2.6.2, organizations should consider the following AI-specific particularities:</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.3.1 shall apply. 6.3.1.3 AI-specific particularities There are no additional activities or tasks defined in the project planning process. When implementing the activities and tasks in 6.3.1.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.3.2 shall apply. 6.3.2.3 AI-specific particularities There are no additional activities or tasks defined in the project assessment and control process.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.3.3 shall apply. 6.3.3.3 AI-specific particularities There are no additional activities or tasks defined in the decision management process. When implementing the activities and tasks in 6.3.3.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.3.4 shall apply. 4) Under preparation. Stage at the time of publication: ISO/IEC DTS 25058:2023</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">If the AI system is related to safety, in order to establish accountability, the organization shall have an audit trail, including elements such as data provenance, data source validation, risk analysis and mitigation, and decisions. This can be recommended to other AI systems, too. Therefore, development of an AI system shall include an audit strategy. For example, storing past decisions together with a reference to the model used including a trail on how that model was created. This can include documenting key decisions in the development process itself and their rationale (e.g. why a certain</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">of an AI system shall include an audit strategy. For example, storing past decisions together with a reference to the model used including a trail on how that model was created. This can include documenting key decisions in the development process itself and their rationale (e.g. why a certain model was preferred).</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.3.5 shall apply, with the following addition. The project shall implement the following activities in accordance with applicable organization policies and procedures with respect to the configuration management process:</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">The project shall implement the following activities in accordance with applicable organization policies and procedures with respect to the configuration management process:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.3.6 shall apply. 6.3.6.3 AI-specific particularities There are no additional activities or tasks defined in the information management process. When implementing the activities and tasks in 6.3.6.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.3.7 shall apply. In addition, processes for AI-specific measurements shall be considered (e.g. probability of erroneous output) if the AI system is related to safety but they are recommended to other AI systems, too.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">In addition, processes for AI-specific measurements shall be considered (e.g. probability of erroneous output) if the AI system is related to safety but they are recommended to other AI systems, too.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.3.8 shall apply. Quality assurance as part of the quality management process, and the evaluation thereof can take a more prominent role in organizations developing, deploying and monitoring AI systems.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.1 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">activities, the organization shall consider that privacy regulations can prevent the use of personal data for a use case that differs from its original collection intent (see ISO/IEC/IEEE 15288:2023, 6.4.1.3 and ISO/IEC/IEEE 12207:2017, 6.4.1.3). In case of making decisions that can affect individuals negatively, legal requirements can require explanation of what data were used and how data were used.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.2 shall apply. 6.4.2.3 AI-specific particularities There are no additional activities or tasks defined in the stakeholder needs and requirements definition process. When implementing the activities and tasks in 6.4.2.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.3 shall apply. 6.4.3.3 AI-specific particularities There are no additional activities or tasks defined in the system requirements definition process.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.4 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.5 shall apply. 6.4.6 System analysis process The purpose, outcomes, activities and tasks provided in ISO/IEC/IEEE 15288:2023, 6.4.6 and ISO/IEC/IEEE 12207:2017, 6.4.6 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.6 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The project shall implement the following activities in accordance with applicable organization policies and procedures with respect to the knowledge acquisition process:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The project shall implement the following activities in accordance with applicable organization policies and procedures with respect to the AI data engineering process.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The outcomes provided in ISO/IEC/IEEE 15288:2023, 6.4.7 and ISO/IEC/IEEE 12207:2017, 6.4.7 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.7</td>
              <td class="req-text">6.4.7 shall apply, with the following addition. The project shall implement the following activities in accordance with applicable organization policies and procedures with respect to the AI model engineering part of the implementation process.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.7</td>
              <td class="req-text">The project shall implement the following activities in accordance with applicable organization policies and procedures with respect to the AI model engineering part of the implementation process.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.10</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.8 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.11.2</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.9 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.12.2</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.10 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.13.2</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.11 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.14.3</td>
              <td class="req-text">The project shall implement the following activities in accordance with applicable organization policies and procedures with respect to the continuous validation process:</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.15.2</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.12 shall apply.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.16.2</td>
              <td class="req-text">ISO/IEC/IEEE 12207:2017, 6.4.13 shall apply, with the following addition. The project shall implement the following activities in accordance with applicable organization policies and procedures with respect to the maintenance process:</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (83)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">where IEC 62304:2006+A1:2015[19] applies. Organizations should consider the AI specifics described in this document together with IEC 62304:2006+A1:2015[19] when implementing such domain specific standards</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">performed concurrently. Nevertheless, a piece of functionality first should be implemented before it can be verified and then deployed.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">The acquisition process described in ISO/IEC/IEEE 15288 and ISO/IEC/IEEE 12207 should be extended beyond the acquisition of products or services to include the possible acquisition of data for the AI data engineering process (see 6.4.8). This new kind of acquisition activity can introduce new acquisition issues such as costs, dependencies, continuity, availability and issues with data rights, rules and legal requirements regarding the use of the acquired data. For example, contracting and acceptance of training data is an important issue because contracting and acceptance of datasets is very difficult</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">activities and tasks in 6.1.2.2, the supplier should consider the following AI-specific particularities to propose, negotiate and agree with the acquirer of the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">implementing the activities and tasks in 6.2.3.2, organizations should consider the following AI-specific particularities:</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">‚Äî When evaluating projects in the portfolio, specific AI risks should be taken into account (see 6.3.4), as well as AI-specific aspects regarding project planning. For example, experimentation can require long periods for training of acceptable ML models.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">in 6.2.4.2, organizations should consider the skills of these additional roles. Additionally, organizations new to AI should review existing human resources and determine the appropriateness of their competencies.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Additionally, organizations new to AI should review existing human resources and determine the appropriateness of their competencies.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">implementing the activities and tasks in 6.2.5.2, organizations should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Organizations should consider implementation of the AI-specific particularities laid down in their quality management processes, including but not limited to their policies, objectives and procedures.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">implementing the activities and tasks in 6.2.6.2, organizations should consider the following AI-specific particularities:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">‚Äî Elements of an AI system (e.g. datasets, data preparation scripts) should be considered for knowledge management, just like any other system element.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">the activities and tasks in 6.3.1.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">Furthermore, project planning should take into account the various other AI particularities of the processes involved, such as establishing continuous validation (see 6.4.14).</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">When implementing the activities and tasks in 6.3.2.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">implementing the activities and tasks in 6.3.3.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">For example, the organization should determine how the quality of machine learning models is measured when implementing the activity &quot;Analyse the decision information&quot; (see ISO/IEC/IEEE 15288:2023,</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">the activities and tasks in 6.3.4.2, either projects or organizations, or both should consider the following AI-specific particularities as well as should refer to ISO/IEC 23894:2023[11] for the details of risk management of AI systems. The objectives for risk management as defined in ISO/IEC 23894:2023[11] include fairness, privacy, reliability, transparency, explainability, accountability, availability, integrity and maintainability.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">AI-specific particularities as well as should refer to ISO/IEC 23894:2023[11] for the details of risk management of AI systems. The objectives for risk management as defined in ISO/IEC 23894:2023[11] include fairness, privacy, reliability, transparency, explainability, accountability, availability, integrity and maintainability.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">The risk assessment activities should include all risks associated with the AI system and the implementation of appropriate risk treatment measures through a risk treatment plan and relevant risk management records as defined in ISO/IEC 23894:2023[11] provides risk management guidance to organizations which develop, produce, deploy and use products, systems and services that utilize AI. It is not intended for the specific risk management of products and services using AI for objectives such as safety and security. Therefore, organizations that apply AI in products and services with safety and</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">security objectives should consider applicable risk management International Standards in addition to the AI specifics around processes as described in ISO /IEC 23894:2023.[11] Considerations regarding the functional safety of AI systems can be found in ISO/IEC TR 5469:‚Äî.[5] For example, developers of AI systems considered as medical devices, should address risk management in line with International Standards, such as ISO 14971:2019[9].</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">AI systems considered as medical devices, should address risk management in line with International Standards, such as ISO 14971:2019[9].</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">in which the system can operate. For example, an automated climate control system should not allow heating above dangerous temperature ranges. Certain rules can also help to manage risks, such as do not open the trunk automatically at high speeds, even if the driver seems to have requested it. The most advanced type of on-going risk management is when an AI system actively performs a decision risk analysis through reasoning, based on a model of the world and rules. Apart from autonomous risk management, risk of harm can be mitigated by sufficient test case coverage, to verify that harmful</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">plan should also address risks related to the objectives as identified by the organization. Organizations should identify potential risks and opportunities related to the AI system including conferring with representative users and other stakeholders to ascertain their needs and requirements (6.4.2).</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.3.3</td>
              <td class="req-text">Organizations should identify potential risks and opportunities related to the AI system including conferring with representative users and other stakeholders to ascertain their needs and requirements (6.4.2).</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">implementing the activities and tasks in 6.3.5.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">from code and configuration files. In some cases of AI systems, the older data repository should be kept intact for the possible need of application version rollback. This can lead to choices that can compromise typical practice for traditional software, such as shorter retention periods of versions.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">In the design and development stages, the organization should consider AI-specific source code management controls associated with AI-specific particularities (e.g. AI data engineering, model training).</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">implementing the activities and tasks in 6.3.6.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">learning datasets for training. These datasets are part of the information that should be managed (see 6.4.8).</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">the activities and tasks in 6.3.8.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">accountability, robustness) should be additionally included. Further information on the quality aspects of AI system can be found in ISO/IEC 25059:2023[16] and ISO/IEC TS 25058:‚Äî[6].</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">In addition, the processes to be evaluated should include activities for conducting analysis during the proof-of-concept, tasks for analysing requirements and risks to ensure adequate coverage of the problem domain of interest, iterative tasks for conducting machine learning, or procedures for creating training data (collection, selection, generation, validation, and modification or addition).</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.8</td>
              <td class="req-text">Examples of effects that should be monitored by means of quality assurance include:</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.8</td>
              <td class="req-text">Quality assurance activities should be appropriate to the use of the AI system. Typically, the complexity of the environment, the level of autonomy exercised, as well as the impact of the output of the AI system influences the level to which organizations should implement quality assurance activities. Moreover, there can be external factors such as regulatory requirements and quality system requirements that affect the type and extent of quality assurance activities. Especially for continuous learning AI systems, organizations should consider appropriate revalidation activities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.8</td>
              <td class="req-text">influences the level to which organizations should implement quality assurance activities. Moreover, there can be external factors such as regulatory requirements and quality system requirements that affect the type and extent of quality assurance activities. Especially for continuous learning AI systems, organizations should consider appropriate revalidation activities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.8</td>
              <td class="req-text">organizations should consider appropriate revalidation activities. See 6.2.5, 6.4.11, 6.4.13, 6.4.14 and the description of data quality analysis in 6.4.8 for details.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">implementing the activities and tasks in 6.4.1.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">should consider the following AI-specific particularities. Due to the inductive nature of AI systems, it is crucial to execute the task to &quot;obtain explicit agreement on the stakeholder requirements&quot;; including critical performance measures that enables the assessment of technical achievement as a target (see ISO/IEC/IEEE 15288:2023, 6.4.2.3 and ISO/IEC/IEEE 12207:2017, 6.4.2.3). Organizations should consider the possibility of introduction of biases by narrow views of stakeholders.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">6.4.2.3). Organizations should consider the possibility of introduction of biases by narrow views of stakeholders.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">Such a technical achievement should be specified by the organization to allow for monitoring of the targets through the quality assurance process (see 6.3.8).</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">The use of the AI system can define particular stakeholder types that should be considered. Particular types of stakeholders to consider include:</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">should further study and refine the values to the extent they can become part of the system requirements. Regulation, human rights, social responsibilities and environmental frameworks can help in refining and describing the values. See ISO/IEC 22989:2022, 5.17 for more details of possible AI stakeholder types.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">requirements should not imply any specific implementation. 6.4.3.2 Outcomes, activities and tasks The outcomes, activities</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">When implementing the activities and tasks in 6.4.3.2, either projects or organizations, or both should consider the following for AI systems:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">type of model used, should be defined.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">the algorithm and data for certain groups in society. Furthermore, AI system decisions should be based on clear and interpretable features so that fairness can be verified. Fairness metrics should be defined in order to set these requirements.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">based on clear and interpretable features so that fairness can be verified. Fairness metrics should be defined in order to set these requirements.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">For a knowledge-based AI system, the knowledge should be coded explicitly in the model. Data analysis (see 6.4.8) can play a part in gathering and refining knowledge.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">engineering, the extracted knowledge should be formalized in such a way that the algorithms involved can utilize it. This is part of the Implementation process (see 6.4.9).</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">based on an input image, and therefore data should be gathered to constitute such input-output combinations. Typical forms of data are structured data, text, sound, image and other sensory data.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">by detecting snow. In order to prevent such generalization issues, test data should have been collected from a different source.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Data acquisition and selection should be an ongoing or recurring process in situations where the relation between the input and output variables changes over time. For example, in order to predict the selling price for a piece of land, it is important to keep up to date with changes in the economy and the market, which are reflected in new data. This new data can be used to test the model regularly and when necessary to retrain, or re-engineer the model (see 6.4.14). Older data that represents outdated relations should be retired for the same reasons.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">relations should be retired for the same reasons.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Persons performing the labelling should be competent in the domain of what is being labelled and trained on the use of the labelling tool. Depending on the risk of the application, labelling results can be subject to review and correction, if necessary.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">When making use of tools to support the labelling of data, organizations should consider the status of the tools used for the labelling process. Such considerations should include an evaluation of the features and functionalities of such annotation tools and the proper validation of such tools to ensure the high quality of labelled data (reference is made to 6.4.8.3, e) and f)).</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">the tools used for the labelling process. Such considerations should include an evaluation of the features and functionalities of such annotation tools and the proper validation of such tools to ensure the high quality of labelled data (reference is made to 6.4.8.3, e) and f)).</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">of data. Data should be of sufficient quantity and bias should be within acceptable limits. It should be sufficiently complete (broad and varied) to be representative of the expected production data. Training data preferably has the same balance (distribution) as the model can expect to see, yet it is necessary to consider specific edge cases.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">‚Äî sensitive data that should be protected from unauthorized internal or external access. In some situations, data augmentation can help to increase the volume of data to create a better model or to perform more testing (e.g. rotating images).</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.7</td>
              <td class="req-text">d) Knowledge programming: After knowledge has been acquired (see 6.4.7) it should be formalized in a heuristic model where the computations are either engineered explicitly (procedural ‚Äì more according to traditional software programming) or implicitly by either specifying rules or probabilities (declarative), or both.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.7</td>
              <td class="req-text">When implementing the activities and tasks of this process, organizations should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.11.3</td>
              <td class="req-text">and tasks in 6.4.11.2, this process should be extended beyond the verification of systems to include the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.11.3</td>
              <td class="req-text">The first AI-specific particularity that should be considered in the verification process is the verification through behaviour.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.11.3</td>
              <td class="req-text">should be verified statistically. As AI models transfer an input to an output, verification of models typically happens by using verification datasets containing inputs and desired output and applying the statistical techniques to measure the desired correctness and robustness (see the system requirements definition process in 6.4.3). The datasets for verification can be collected from a separate and distinct subset of the same source of the training data or from a different source. The advantage of the latter is that a different</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.11.3</td>
              <td class="req-text">The organization should make sure that source code involved with AI is included in regular reviews of code quality aspects, such as maintainability, testability and reusability (e.g. peer reviews of training scripts or unit testing of data preparation code similar to source code that is not involved with AI).</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.12.3</td>
              <td class="req-text">activities and tasks in 6.4.12.2, either projects or organizations, or both should consider the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.12.3</td>
              <td class="req-text">The organization should aim to support model updates (retraining or knowledge engineering) and the execution of continuous monitoring of established metrics associated with the use of the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.12.3</td>
              <td class="req-text">The organization should assess how performance of the AI system can be affected after it has been put into use and, by allowing for such factors, design appropriate monitoring metrics. An AI system, once deployed, can exhibit unexpected behaviour (e.g. as a result of bias or being exposed to unexpected input), and therefore monitoring performance is important, and procedures and processes can be more extensive compared to traditional systems.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.12.3</td>
              <td class="req-text">As some AI systems have the ability to improve their performance over time, the organization should support the attainment of quality of such improvements by implementing a quality management process. For example, monitoring trends of the amount of use associated with the use of the AI system can support the organization ensuring its continued &quot;quality in use&quot;.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.13.3</td>
              <td class="req-text">and tasks in 6.4.13.2, this process should be extended beyond the validation of systems to include the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.13.3</td>
              <td class="req-text">The organization should aim to support model updates (retraining or knowledge engineering) and the execution of continuous monitoring of established metrics associated with the use of the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.13.3</td>
              <td class="req-text">The organization should assess how performance of the AI system can be affected after it has been put into use. And, by allowing for such factors, design appropriate monitoring metrics. An AI system, once deployed, can exhibit unexpected behaviour (e.g. as a result of bias or being exposed to unexpected input), and therefore monitoring performance is important, and procedures and processes can be more extensive compared to traditional systems.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.13.3</td>
              <td class="req-text">As some AI systems have the ability to improve their performance over time, the organization should support the attainment of quality of such improvements by implementing a quality management process. For example, monitoring trends of the amount of use associated with the use of the AI system can support the organization ensuring its continued &quot;quality in use&quot;.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.14.1</td>
              <td class="req-text">human interaction, an automated rollback process, at defined thresholds, should be included to prevent undesired model changes.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.14.3</td>
              <td class="req-text">Determine the frequency at which validation should occur.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.15.3</td>
              <td class="req-text">and tasks in 6.4.15.2, this process should be extended beyond the operation of systems to include the following AI-specific particularities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.15.3</td>
              <td class="req-text">The second AI-specific particularity is that the organization should consider early in the life cycle the production data which the AI system will operate on. Considerations can include availability, fit for intended behaviour, diversity of features, consistency between training, test and production data while leveraging independent datasets when applicable. Such considerations can, for example, translate into functional and technical specifications, user guides or user specifications, or production data metrics.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.15.3</td>
              <td class="req-text">The organization should aim to support model updates (retraining or knowledge engineering) and the execution of continuous monitoring of established metrics associated with the use of the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.15.3</td>
              <td class="req-text">The organization should assess how performance of the AI system can be affected after it has been put into use. And, by allowing for such factors, design appropriate monitoring metrics. An AI system, once deployed, can exhibit unexpected behaviour (e.g. as a result of bias or being exposed to unexpected input), and therefore monitoring performance is important, and procedures and processes can be more extensive compared to traditional systems.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.15.3</td>
              <td class="req-text">As some AI systems have the ability to improve their performance over time, the organization should support the attainment of quality of such improvements by implementing a quality management process. For example, monitoring trends of the amount of use associated with the use of the AI system can support the organization ensuring its continued &quot;quality in use&quot;. Additionally, all incidents, include system failures and data errors, should be reported and assessed.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.15.3</td>
              <td class="req-text">system failures and data errors, should be reported and assessed.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.16.3</td>
              <td class="req-text">should be extended beyond the maintenance of systems to include the activities of continuous learning. Just like with traditional software system development, maintenance can include all the activities that take place in earlier processes, especially the implementation process. Design and implementation can evolve constantly. The same goes for AI systems. Models can require retraining or other updates (see model engineering as part of the implementation process in 6.4.9). New training data can be collected and data preparation can be changed, in order for the system to keep functioning properly while either</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.16.3</td>
              <td class="req-text">As some AI systems have the ability to improve their performance over time, the organization should support the attainment of quality of such improvements by implementing a quality management process. For example, monitoring trends of the amount of use associated with the use of the AI system can support the organization ensuring its continued &quot;quality in use&quot;.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (3)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Reliability-002</code></td><td>Reliability</td><td>Level 1</td><td style="font-size:0.85em">[System] implements reliability monitoring and rollback mechanism per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Efficiency-003</code></td><td>Efficiency</td><td>Level 1</td><td style="font-size:0.85em">[System] documents resource utilization tradeoffs and optimization strategy per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Availability-003</code></td><td>Availability</td><td>Level 1</td><td style="font-size:0.85em">[System] has documented maintenance and availability monitoring plan per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-05" data-shall="0" data-should="0">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-05')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">05</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC DTR 5469</span>
        <span class="badge badge-dtr">DTR</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">AI Functional Safety</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 0</span>
        <span id="arrow-TC-DOC-05" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-05" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Controllability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Explainability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Functional Correctness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Intervenability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Resilience</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Security</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHOULD statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (5)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Safety-001</code></td><td>Safety</td><td>Level 2</td><td style="font-size:0.85em">[System] implements safety architecture Class [I/II/III] with [mechanism] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Safety-002</code></td><td>Safety</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves safety integrity level [SIL/ASIL] with residual risk &lt; [threshold] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Availability-001</code></td><td>Availability</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves availability ‚â• [X]% (SLA) with MTTR ‚â§ [Y] hours per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Availability-002</code></td><td>Availability</td><td>Level 2</td><td style="font-size:0.85em">[System] implements fault-tolerant architecture with documented backup/recovery procedure per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Resilience-001</code></td><td>Resilience</td><td>Level 2</td><td style="font-size:0.85em">[System] demonstrates graceful degradation with performance ‚â• [X]% under [failure condition] per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-06" data-shall="38" data-should="30">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-06')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">06</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC DTS 12791</span>
        <span class="badge badge-dts">DTS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Bias Treatment in AI</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 38</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 30</span>
        <span id="arrow-TC-DOC-06" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-06" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Accountability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Bias/Fairness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Controllability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Functional Correctness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (38)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">An organization shall identify requirements that relate to unwanted bias within an AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.2</td>
              <td class="req-text">An organization shall define and document operating conditions under which an AI system is intended to be used and be evaluated for bias.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.2</td>
              <td class="req-text">AI producers or AI partners shall make information available regarding systems aspects that can affect unwanted bias.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.2</td>
              <td class="req-text">Information made available by data providers shall include: ‚Äî data provenance (including for training, validation and testing data).</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.3</td>
              <td class="req-text">Stakeholder identification shall be conducted throughout the development of an AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.3</td>
              <td class="req-text">Organizations responsible for the deployment or operation of an AI system shall also consider: ‚Äî AI subjects that are subject to an automated decision or who share an operating environment with an AI system; ‚Äî data subjects who do not directly interact with an AI system, but nevertheless are vulnerable to harm due to their presence in training data; ‚Äî data subjects who do not directly interact with an AI system but whose data are used in training.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.4</td>
              <td class="req-text">An organization shall document the sources of data used by the AI system and consider bias in relation to each source.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.4</td>
              <td class="req-text">Representative training data and representative test data shall be used.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.4</td>
              <td class="req-text">Where appropriate for the use case, the following aspects of each data source shall be evaluated and documented: ‚Äî completeness, including the number of missing features for each group of relevant stakeholders; ‚Äî accuracy, including the amount of inaccurate data contained within the data set, and the amount of inaccuracy for each group of relevant stakeholders; ‚Äî collection procedures, including the lineage of the data, and the collection, input or labelling mechanism; ‚Äî timeliness, including the effect of the time of collection on accuracy; ‚Äî consistency, including labels.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.5</td>
              <td class="req-text">An organization shall identify risks related to unwanted bias that can occur during the design, development, deployment and use of an AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.5</td>
              <td class="req-text">An organization shall assess and treat these identified risks to identified and affected AI stakeholders.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.5</td>
              <td class="req-text">Consideration shall be given to at-risk groups that are not explicitly identified as belonging to any group in the training data or production data.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.7</td>
              <td class="req-text">An organization shall determine appropriate tolerances for functional correctness for different at-risk groups.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.7</td>
              <td class="req-text">The choice of acceptance criteria shall be justified in the documentation, in consideration of the risk management process.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.7</td>
              <td class="req-text">Where acceptance criteria are specified in relation to ML model outputs, they shall be specified in a quantitative manner.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2.1</td>
              <td class="req-text">An organization shall document the rationale for how they represent training in features that are interpreted by the ML model.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2.1</td>
              <td class="req-text">Where risks have been identified in relation to unwanted bias, the organization shall consider: ‚Äî types of data biases that can be present and the effect of feature selection; ‚Äî types of cognitive biases that can be present in the humans selecting features or labelling and annotating data; ‚Äî missing or unexpected feature values and data skew; ‚Äî interactions between multiple ML models or system components; ‚Äî biases that result from the disproportionate availability of data sets, features, labels or annotations of data.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2.4</td>
              <td class="req-text">When data bias is identified during the training process, an organization shall consider adjusting the data to treat the risk of unwanted bias.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.1</td>
              <td class="req-text">Testing shall be performed in two ways, static testing of data and dynamic testing of the model and AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.1</td>
              <td class="req-text">The test approach used shall be documented in a test plan in accordance with ISO/IEC/IEEE 29119-3:2021, 7.2.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.1</td>
              <td class="req-text">The test completion report shall include criteria for when verification and validation activities are repeated, including continuous monitoring.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.2</td>
              <td class="req-text">The data quality evaluation process shall be conducted in accordance with ISO/IEC 5259-4:‚Äî, 6.3, including measuring training data quality for each at-risk group that has been identified in relation to unwanted bias.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.2</td>
              <td class="req-text">The evaluation shall include the following measures described in ISO/IEC 5259-2:‚Äî for each at-risk group: ‚Äî auditability, including whether it is possible to establish the source of the data; ‚Äî balance; ‚Äî currentness, including whether the data are sufficiently relevant; ‚Äî completeness, including the number of missing features; ‚Äî accuracy, including the amount of inaccurate training data contained within the data set.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.2</td>
              <td class="req-text">If the training data does not directly contain an identifier that explicitly links each record to an at-risk group, this shall be provided to the data quality checking process as metadata if the group is identifiable.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">An AI system shall be dynamically tested to determine if it exhibits unwanted bias.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">Test data separate from the training data shall be used.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">Model testing shall be conducted on the ML model.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">The testing shall also be conducted on the whole AI system that uses the ML model.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">The comparative functional correctness of the outputs shall be evaluated amongst at risk groups, using appropriate metrics, to determine whether the AI system meets the acceptance criteria.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">The system shall be evaluated amongst at-risk groups to determine if differences in the quality of the outputs can be observed.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">The organization shall determine if these differences are acceptable against the acceptance criteria.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">The rationale for the selection of appropriate metrics shall be documented.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">Testing with users shall be undertaken to determine if user interface design choices or automation bias in users reinforce bias in the system.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">Extreme data inputs for each at-risk group shall also be tested in order to identify variations in the robustness of the ML model that can result in unwanted bias.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">An organization shall document their approach to ensuring that the risk treatments identified to address unwanted bias continue to have the desired effect on an ongoing basis.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">This approach shall provide appropriate methods to treat the risks of unwanted bias occurring without detection and shall include criteria for when all verification activities shall be conducted again.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">This shall include consideration of any continuous learning or model retraining, and changes in surrounding data pipelines and user interfaces.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">Organizations shall ensure there is appropriate logging to support and monitor the selected unwanted bias risk treatments.</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (30)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.1.2</td>
              <td class="req-text">The level of definition and documentation should be commensurate with the role of the organization within the AI life cycle.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.2</td>
              <td class="req-text">For example, an organization producing a pre-trained ML model should anticipate a broad number of scenarios of use, while an organization conducting a live deployment should more precisely specify the operational conditions.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.2</td>
              <td class="req-text">This document should be applied to elements (including data) of an AI system that are being procured or built.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.2</td>
              <td class="req-text">An organization should ensure that commercial agreements with third parties include appropriate measures to treat the risk of bias, in particular where an organization is unable to obtain full transparency on technical aspects of the system.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.2</td>
              <td class="req-text">Information made available by AI technology providers should include: ‚Äî trade-offs in ML algorithm development; ‚Äî data quality processes that can relate to bias such as imputation or augmentation; ‚Äî testing strategies used during the verification and validation stage of the system development (including acceptance criteria).</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.2</td>
              <td class="req-text">Information made available by data providers should include: ‚Äî information on the relevant working conditions for data labelling workers; ‚Äî the geographic locations in which the data labelling was undertaken; ‚Äî salient aggregated demographic patterns of the data labelling workforce.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.2</td>
              <td class="req-text">Data providers should ensure that privacy of individual workforce members is maintained in accordance with this guidance.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.3</td>
              <td class="req-text">As well as those directly using or gaining benefit from the implementation of an AI system, any individuals, groups or organizations who can be affected by the system should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.4</td>
              <td class="req-text">Multiple data sources may be used to achieve a sufficient level of representation across stakeholder groups; however, these should also be reviewed to consider whether the combination of data sets can introduce additional risks relating to data bias.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.5</td>
              <td class="req-text">ISO/IEC 23894 should be used in conjunction with this document.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.5</td>
              <td class="req-text">The following documents should also be used: ‚Äî ISO/IEC 25059 to identify quality measures that can vary by at-risk group; ‚Äî ISO/IEC 5259-2:‚Äî to identify data quality measures that can vary by at risk group; ‚Äî the documentation of data sources referenced in 5.1.4.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.6</td>
              <td class="req-text">The implementation of techniques of evaluation for bias should consider: ‚Äî relevant groups of identified stakeholders and users; ‚Äî geographical or cultural contexts; ‚Äî the operational conditions of the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.7</td>
              <td class="req-text">These should be defined in advance of evaluating an AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.7</td>
              <td class="req-text">Relevant AI stakeholders should be included in the definition process.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.7</td>
              <td class="req-text">Bias in an AI system should be re-evaluated to consider resulting changes (such as to metrics, risks, stakeholders or requirements) and addressed accordingly.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.7</td>
              <td class="req-text">Acceptance criteria should be documented in the context of the intended use and operating conditions.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1.7</td>
              <td class="req-text">Acceptance criteria for the system should be testable.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2.2</td>
              <td class="req-text">Labelling should be sufficient to identify potential sources of unwanted bias.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2.2</td>
              <td class="req-text">Data labels or documentation of a data set should enable data to be evaluated for unwanted bias.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2.3</td>
              <td class="req-text">An organization should implement mechanisms to ensure labelling or annotation is of sufficient quality to meet AI system objectives, including where it is performed by humans.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2.5</td>
              <td class="req-text">When unwanted bias remains, an organization should implement and document mechanisms to prevent identified risks from occurring.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2.5</td>
              <td class="req-text">An organization should consider: ‚Äî further data-based methods; ‚Äî model-based methods; ‚Äî post-hoc methods.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.1</td>
              <td class="req-text">The test results should be recorded in a test completion report in accordance with ISO/IEC/IEEE 29119-3:2021, 7.4.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">Component testing should be conducted on the automated data pre-processing steps (see ISO/IEC 23053:2022, 8.3) as part of the development process.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">The testing should be comprehensive enough to be representative of the expected input data in production usage.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">Evaluation of unwanted bias should be conducted in the context of the intended use and the target operational conditions.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">The following additional risk treatments should be considered in the approach: ‚Äî monitoring of unwanted bias during operation; ‚Äî monitoring of changes in the training data profile where model retraining occurs; ‚Äî technical mechanisms to alert operators if processing is outside of defined usage limits; ‚Äî technical mechanisms to identify if production data contains inputs that are outside of those assessed in verification activities; ‚Äî mechanism for end users to identify potential unwanted bias and bring it to the attention of operators; ‚Äî human-in-the-loop mechanisms.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">An organization should also ensure that documentation and data are retained to support repurposing of the training data or ML model, or investigating historical incidents or potential unwanted bias after disposal.</td>
            </tr>
            <tr>
              <td class="clause-col">6</td>
              <td class="req-text">However, applicable techniques should be selected during the life cycle inception stage.</td>
            </tr>
            <tr>
              <td class="clause-col">7</td>
              <td class="req-text">Selection of the appropriate aggregation algorithm is important and should be done considering the data distribution across the participating nodes.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (3)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Bias-Fairness-001</code></td><td>Bias/Fairness</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves demographic parity gap &lt; [X]% across [protected attributes] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Bias-Fairness-002</code></td><td>Bias/Fairness</td><td>Level 2</td><td style="font-size:0.85em">[System] implements bias risk management covering [protected groups] with documented acceptance criteria per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Bias-Fairness-003</code></td><td>Bias/Fairness</td><td>Level 1</td><td style="font-size:0.85em">[System] has documented bias identification process with stakeholder identification per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-07" data-shall="0" data-should="12">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-07')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">07</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC DTS 6254</span>
        <span class="badge badge-dts">DTS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Explainability Methods</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 12</span>
        <span id="arrow-TC-DOC-07" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-07" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Controllability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Explainability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Functional Correctness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Intervenability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#fff3cd;color:#856404;border:1px solid #ffc107;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Interpretability ‚¨Ü (PROXY)</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (12)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">6.10</td>
              <td class="req-text">An example scenario is for a loan applicant whose application was denied due to automated credit risk assessment, to understand what they should change to get the loan.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4</td>
              <td class="req-text">Evaluation of the explainability component should take it into account.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4</td>
              <td class="req-text">More precisely, if the AI system itself is deterministic, then the same input should deterministically trigger the same explanation.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4</td>
              <td class="req-text">For non-deterministic AI systems, the explanation should change only when the change in the decision process is relevant for its understanding.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4.2.7</td>
              <td class="req-text">Explanations should be robust to minor modification in the system&#x27;s behaviour.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4.2.7</td>
              <td class="req-text">In other words, a minor modification in the decision process should not change the explanation in a significant way.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4.2.7</td>
              <td class="req-text">For a model that has a smooth behaviour (a minor modification in the input does not change the behaviour in a significant way), this means that a minor modification in the input should not change the explanation in a significant way.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4.2.7</td>
              <td class="req-text">If a minor change in the input results in a large change in the decision process of the model, this effect should propagate to the explanation subsequently, and a large change in the explanation can be appropriate.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4.2.7</td>
              <td class="req-text">If the expected decision is itself discontinuous, then the explanation should be affected in the same way as the model: if the model (correctly) has unstable behaviour, then the corresponding explanation should also be unstable; if the model (incorrectly) keeps a smooth behaviour, the explanation should also be stable, which enables stakeholders to detect that issue of the model.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4.2.7</td>
              <td class="req-text">The general expectation is that a robust explanation should inform on relevant perturbations that affect the decision process beyond a certain margin.</td>
            </tr>
            <tr>
              <td class="clause-col">8.2</td>
              <td class="req-text">For such a non-expert audience, explanations should make limited use of both AI-related technical elements (as for domain experts) and domain-specific elements (as for AI specialists).</td>
            </tr>
            <tr>
              <td class="clause-col">9.3</td>
              <td class="req-text">CEM highlights not only what is minimally and sufficiently present to justify the classification of an input example by a neural network (pertinent positives), but also what should be minimally and necessarily absent (pertinent negatives), in order to form a more complete and well-rounded explanation.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (6)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Transparency-001</code></td><td>Transparency</td><td>Level 1</td><td style="font-size:0.85em">[System] provides transparency documentation covering [aspects] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Transparency-002</code></td><td>Transparency</td><td>Level 2</td><td style="font-size:0.85em">[System] achieves Transparency Level [N] as defined in [standard] with [N] of [M] criteria satisfied‚Ä¶</td></tr>
          <tr><td><code>SC-Transparency-003</code></td><td>Transparency</td><td>Level 3</td><td style="font-size:0.85em">[System] provides real-time explainability logging with audit trail per [standard] verified by [party]‚Ä¶</td></tr>
          <tr><td><code>SC-Explainability-001</code></td><td>Explainability</td><td>Level 2</td><td style="font-size:0.85em">[System] provides [explanation type] explanations achieving faithfulness score ‚â• [X]% per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Explainability-002</code></td><td>Explainability</td><td>Level 1</td><td style="font-size:0.85em">[System] provides stakeholder-appropriate explanations covering [scope] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Explainability-003</code></td><td>Explainability</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves Explainability Level [N] with [metric] ‚â• [value] across [user groups] verified per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-08" data-shall="2" data-should="85">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-08')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">08</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC DTS 8200</span>
        <span class="badge badge-dts">DTS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Controllability of AI Systems</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 2</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 85</span>
        <span id="arrow-TC-DOC-08" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-08" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Controllability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Intervenability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Security</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Authenticity ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Autonomy ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Threat ‚¨Ü</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (2)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">7.2.1.2</td>
              <td class="req-text">The provider of an AI system shall provide users with descriptions and documentation of the AI system&#x27;s controllability features.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.2.1</td>
              <td class="req-text">The start and termination of a learning process shall be controllable.</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (85)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">The design and implementation of controllability should be considered and practiced by stakeholders of an AI system that can impact users, the environment and societies.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">The system state transition target should be identified during design and development and the transitions to a target state should be subject to verification and validation during system testing.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">The following attributes of the intended target state should be identified by the designers, developers, managers, users and any other stakeholders of the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">Stability of the states of an AI system should meet the requirements about control and state observation.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">Target states should be reachable under certain circumstances via actions.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">The inability to reverse side effects should be carefully considered when using AI systems in domains such as material processing and manufacturing.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">When a system is controlled programmatically, functions implementing control logics should be designed.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">When a system is equipped with physical mechanisms for control, such as a steering wheel on an assisted-driving vehicle, safety and usability factors that can affect the effectiveness and efficiency of control should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">In addition to considering the medium (e.g. air or water), distance and noise, the subsystem should also consider expectations for control timeliness and sequencing.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">Therefore, before an actual control is performed the following should be confirmed: ‚Äî that the system can accept and conduct the control instructions from a specific controller.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">If not, either an uncertainty handling mechanism should be prepared or the plan for this control should be cancelled due to the lack of feasibility.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">For this, a preparation process for control transfer should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">The controller derives a plan containing a sequence of actions (e.g. move to correct position for control) that should be taken in order to be ready for the actual operation.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">To handle this, a transaction mechanism should be considered for control transfer which guarantees either the control transfer is entirely successfully performed or entirely not performed if partial failure happens.</td>
            </tr>
            <tr>
              <td class="clause-col">6.6</td>
              <td class="req-text">In addition, a set of criteria should be met when performing a specific action or a sequence of actions.</td>
            </tr>
            <tr>
              <td class="clause-col">6.6</td>
              <td class="req-text">To control the AI system, the engagement of control process should be prepared in advance to plan a sequence of actions and satisfy the corresponding criteria.</td>
            </tr>
            <tr>
              <td class="clause-col">6.6</td>
              <td class="req-text">The engagement of control should be configured or planned in advance for each possible control in order to decrease uncertainty and infeasibility.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">To handover the control of the AI system, a disengagement of control process should be prepared in advance.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">Preparation should include the generation of a plan for possible detachment.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">Transactional mechanism should be also prepared for a disengagement of control process where partial failure can happen during the relinquishment of multiple control points.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">For this, similar keys in 6.6 should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">For a transfer of control the capacity of the controller should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">Uncertainty should be handled when a failure happens, and particularly in the cases that can lead to loss of asset, performance, or any other results and risks unacceptable to both the controller and the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">In any case, a default uncertainty handling mechanism should be considered and implemented to stop or pause the current action of an AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">To minimize the chance an AI system is out of control, the following actions should be considered to handle uncertainty: ‚Äî Identify atomic operations.</td>
            </tr>
            <tr>
              <td class="clause-col">6.9</td>
              <td class="req-text">The resources required should be checked when the controller or the AI system under control has limited resources.</td>
            </tr>
            <tr>
              <td class="clause-col">6.9</td>
              <td class="req-text">An estimation of resource consumption should be considered during the process of control.</td>
            </tr>
            <tr>
              <td class="clause-col">6.9</td>
              <td class="req-text">The cost of control for the controller, the AI system, other entities and the environment should be estimated and checked.</td>
            </tr>
            <tr>
              <td class="clause-col">6.9</td>
              <td class="req-text">Therefore, the following should be checked: a) whether the magnitude of resources required by a control exceeds the limits of the system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.9</td>
              <td class="req-text">Trade-offs between the cost of control and the system&#x27;s quality requirements based on ISO/IEC 25059 should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">6.9</td>
              <td class="req-text">Once estimated, the cost of control should be provided to the controller or intended stakeholders of an AI system, who determines the acceptability of the cost and takes further actions about control of the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.10.2</td>
              <td class="req-text">The following should be checked when estimating the cost of a control transfer: a) whether the control transfer makes use of resources that are required by the system&#x27;s functioning; b) whether the control transfer makes use of a number of resources exceeding the system limits; c) whether the control transfer can lead to an out of control state.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">To realize the controllability of an AI system, the following should be considered: a) The states of an AI system should be observable and transitionable.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">For this, an AI system should provide functionalities by which a controller can observe the system states or at least obtain relevant information.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">For systems that provide non-fully-explainable subprocesses, those subprocesses should be controllable such that the potential hazards caused by unpredicted behaviours can be intervened and restricted.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The subprocesses that carry out sampling to those that return a system state should be controllable.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">In this context, a system state should be provided without any precondition except for authorization and authentication checks.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The sequence of subprocesses should be controllable that execute the control instructions.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">In this context, the AI system should be able to accept and execute all control instructions.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The subprocesses for learning policy determination should be controllable.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.1</td>
              <td class="req-text">Controllability features should be planned during the inception or design and development stages of the AI system life cycle.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.1</td>
              <td class="req-text">The use of controllability features for risk identification and treatment should be prepared.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.3</td>
              <td class="req-text">The start and termination of an inference process should be controllable.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.3</td>
              <td class="req-text">For systems using a sequence of operations realized by executing multiple machine learning models, controls should be available on the transition between the execution of different models.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.3</td>
              <td class="req-text">The observation of all system states should be enabled.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.3</td>
              <td class="req-text">The observations to the input and output values of the following should be enabled: 1) entire system, 2) a module of the system.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.3</td>
              <td class="req-text">The observations to machine learning-based AI system execution logs and errors should be enabled.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.3</td>
              <td class="req-text">When an AI system provides both asynchronous and synchronous modes for the execution of its subprocesses, controls should be available for controlling switching between the two modes.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.4</td>
              <td class="req-text">The start and termination of a reasoning process should be controllable.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.4</td>
              <td class="req-text">When a system is able to perform automated reasoning over multiple kinds of knowledge representations, the selection and use of reasoners should be controllable.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.4</td>
              <td class="req-text">The input data to and the output data from a reasoner should be observable.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.1.4</td>
              <td class="req-text">The observation of system execution logs and errors should be enabled.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.2.1</td>
              <td class="req-text">For AI systems using neural networks, during backpropagation, gradient values of a relevant part of a neural network should be observable.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.2.1</td>
              <td class="req-text">For AI systems that automatically determine the content to learn, the selection and change of the content to learn should be controllable.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2.2.2</td>
              <td class="req-text">For semantic computing-based continuous learning system, the following should be controllable: a) selection of the ontologies to be built as well as the priorities of new knowledge to be merged; b) selection of the ontologies on which knowledge computing is performed.</td>
            </tr>
            <tr>
              <td class="clause-col">8.1</td>
              <td class="req-text">Stakeholders should consider the following principles during the crucial AI system life cycle design and development stage.</td>
            </tr>
            <tr>
              <td class="clause-col">8.1</td>
              <td class="req-text">To improve the effectiveness and efficiency of controllability, design and development should not depend on the AI system&#x27;s functionality implementation.</td>
            </tr>
            <tr>
              <td class="clause-col">8.1</td>
              <td class="req-text">A &#x27;stop&#x27; control that stops an AI system from executing its current task should be always considered during design and development.</td>
            </tr>
            <tr>
              <td class="clause-col">8.1</td>
              <td class="req-text">Developers should consider the set points and other forms of algorithmic goals of such systems, the appropriateness and sufficiency of behavioural constraints put in place, and what bearing these have on ensuring the system remains in a safe state and, in adverse situations, recovers from unsafe states.</td>
            </tr>
            <tr>
              <td class="clause-col">8.2</td>
              <td class="req-text">During the inception stage of an AI system, controllability functionalities should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">8.2</td>
              <td class="req-text">For each interaction between a controller and an AI system, the following should be analysed and recorded: i) causal relationship between a controller&#x27;s instruction and the behaviour or appearance the system should exhibit.</td>
            </tr>
            <tr>
              <td class="clause-col">8.2</td>
              <td class="req-text">This should be done in particular to prevent or stop an AI system from doing harm.</td>
            </tr>
            <tr>
              <td class="clause-col">8.2</td>
              <td class="req-text">The following should be performed by stakeholders: Controllability scenario identification discovers the scenarios where control or state observation functionalities are needed.</td>
            </tr>
            <tr>
              <td class="clause-col">8.2</td>
              <td class="req-text">The funding-related cost for controllability functionalities should be forecast for the AI system over its entire system life cycle.</td>
            </tr>
            <tr>
              <td class="clause-col">8.2</td>
              <td class="req-text">For safety-critical AI systems, requirements should be identified before the system (any software or hardware) design is undertaken, as it is usually not possible to retrofit safety design features.</td>
            </tr>
            <tr>
              <td class="clause-col">8.3.5</td>
              <td class="req-text">Controllability features should be designed in order to technically satisfy the needs of planned risk assessment and treatment activities for an AI system, according to ISO/IEC 23894:2023, 6.4 and 6.5.</td>
            </tr>
            <tr>
              <td class="clause-col">8.4</td>
              <td class="req-text">For this, the following suggestions should be considered: a) Separate the ownership and use of computing resources (e.g. memory, communication bandwidth and processor) between controllability and system functionalities.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">Verification should include the following: a) Identify controllability functionality requirements that an AI system should provide, including control and state observation.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">This work should be done during the inception stage.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">If this identification has not been done before verification, it should be done before testing of controllability.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">A parameter should be considered if it can potentially affect the results of control or state observation.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">The actual outputs of a controllability functionality should be compared with the expected and unexpected effects and side effects.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">For a requirement on controllability, at least the functional correctness and efficiency should be compared.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">Other aspects of efficiency required in a specific scenario should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">The verified controllability functionalities should be listed with their expectations and actual results.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">The verification process of an AI system&#x27;s controllability should be documented.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">Functional testing of functional safety controllability functionalities should use 9.1.3 b).</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">The identification of scenarios should be done during the inception stage.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">If the identification of scenarios is not done before validation it should be done before the testing of controllability functionalities.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">For system configurations, user customized and even wrong settings should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">The actual output of the system should be compared with expectations for the identified scenarios.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">The validated controllability functionalities should be documented for each identified scenario along with the scenario expectations and actual outputs.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">The validation process of an AI system&#x27;s controllability should be documented.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">Based on actual live data, the execution and results of controllability should be checked with scenarios.</td>
            </tr>
            <tr>
              <td class="clause-col">Annex B</td>
              <td class="req-text">Expectations of a scenario should also be recorded.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (7)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Security-003</code></td><td>Security</td><td>Level 1</td><td style="font-size:0.85em">[System] implements access control with authentication for all control interfaces per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Controllability-001</code></td><td>Controllability</td><td>Level 2</td><td style="font-size:0.85em">[System] implements Controllability Level [N] with documented stop/override mechanisms per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Controllability-002</code></td><td>Controllability</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves verified controllability with human takeover time &lt; [X] seconds under [conditions] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Controllability-003</code></td><td>Controllability</td><td>Level 1</td><td style="font-size:0.85em">[System] provides user documentation of all controllability mechanisms per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Intervenability-001</code></td><td>Intervenability</td><td>Level 2</td><td style="font-size:0.85em">[System] implements human-in-the-loop review for [decision types] with documented intervention procedure per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Intervenability-003</code></td><td>Intervenability</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves intervention success rate ‚â• [X]% with average intervention time &lt; [Y] minutes per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Resilience-002</code></td><td>Resilience</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves recovery time ‚â§ [X] seconds from [failure type] with data integrity maintained per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-09" data-shall="1" data-should="5">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-09')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">09</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC FDIS 23053</span>
        <span class="badge badge-fdis">FDIS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Framework for AI Systems Using ML</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 1</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 5</span>
        <span id="arrow-TC-DOC-09" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-09" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Functional Correctness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (1)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">For many algorithms, hyperparameters shall also be chosen.</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (5)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">Therefore, care should be taken with the datasets used for training models.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">All aspects of supervised machine learning data are prone to error, and special care should be taken across the full cycle from dataset creation to model testing.</td>
            </tr>
            <tr>
              <td class="clause-col">8.5</td>
              <td class="req-text">However, such practice is to apply with special caution, so that it remains distinct from model selection, which should not be performed on test data.</td>
            </tr>
            <tr>
              <td class="clause-col">8.5</td>
              <td class="req-text">Comparative evaluation should only be conducted for a few models and which are very different (e.g. based on different training data, different ML algorithms or different ML approaches, not just different hyperparameters).</td>
            </tr>
            <tr>
              <td class="clause-col">8.8</td>
              <td class="req-text">It should be noted that the data flows in A.2.2 are not described as flows between functional components within the cloud computing reference architecture (ISO/IEC 17789), but instead provide a view of data flows through the various phases of the ML pipeline and ML model development processes.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-10" data-shall="0" data-should="100">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-10')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">10</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC FDIS 42005</span>
        <span class="badge badge-fdis">FDIS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">AI System Impact Assessment</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 100</span>
        <span id="arrow-TC-DOC-10" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-10" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Accountability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Bias/Fairness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Harm ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Privacy ‚¨Ü</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (100)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">The organization should have a structured and consistent approach for performing and documenting AI system impact assessments. The process used can vary depending on a range of factors.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">The organization should document the process for completing AI system impact assessments. Such documentation should be kept up to date and made available, where appropriate, to relevant interested parties. Documentation of the process should include information on the topics in Clause 5. The intended results of the process documentation can vary depending on the organization&#x27;s needs and the type of the AI system, and can include, for example:</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">documentation should be kept up to date and made available, where appropriate, to relevant interested parties. Documentation of the process should include information on the topics in Clause 5. The intended results of the process documentation can vary depending on the organization&#x27;s needs and the type of the AI system, and can include, for example:</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">parties. Documentation of the process should include information on the topics in Clause 5. The intended results of the process documentation can vary depending on the organization&#x27;s needs and the type of the AI system, and can include, for example:</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">Documentation should be maintained throughout the AI system impact assessment process within the data retention policies of the organization and its legal obligations related to data retention, i.e. at the stages of design, redesign, deployment and evaluation.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">The organization should document how the AI system impact assessment is integrated with other organizational processes. This can include considerations such as:</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">As part of establishing the AI system impact assessment process, the organization should determine and define when such assessments should be performed and to what level, or when a previous AI system impact assessment can be reused, repurposed or revised, and to what extent. Determining the timing of the AI system impact assessments can be impacted by factors such as, but not limited to:</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">and define when such assessments should be performed and to what level, or when a previous AI system impact assessment can be reused, repurposed or revised, and to what extent. Determining the timing of the AI system impact assessments can be impacted by factors such as, but not limited to:</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">The organization should consider reassessment when changes arise in factors such as, but not limited to:</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">AI risk assessments and AI system impact assessments should be conducted prior to implementing the change triggering reassessment.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">The organization should consider whether it uses tools for triaging when an AI system impact assessment is required. For example, if the organization determines that AI system impact assessments are only to be done on &quot;high-risk&quot; AI systems, they should document as part of the process what constitutes a &quot;high-risk&quot; AI system and what triggers the need for an impact assessment. A triaging process can require a briefer version of the AI system impact assessment to determine if the AI system is high-risk and requires a full AI system impact assessment.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">only to be done on &quot;high-risk&quot; AI systems, they should document as part of the process what constitutes a &quot;high-risk&quot; AI system and what triggers the need for an impact assessment. A triaging process can require a briefer version of the AI system impact assessment to determine if the AI system is high-risk and requires a full AI system impact assessment.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">The organization should define the scope of the AI system impact assessment, including the applicability and the boundaries of the AI system impact assessments considering the internal and external factors provided in 5.1, the expectations of relevant interested parties and the reasonably foreseeable impacts on individuals, groups of individuals or societies. The scope of an AI system impact assessment can include, but is not limited to:</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">If a system is composed of interconnected AI systems, the organization should consider whether to perform a single AI system impact assessment.</td>
            </tr>
            <tr>
              <td class="clause-col">5.6</td>
              <td class="req-text">The organization should ensure that the responsibilities for the AI system impact assignment are assigned and communicated within the organization. The relevant responsibilities depend on multiple factors, including the nature of the AI system impact assessment, its scope and its extent, the existence of a previous assessment, and can include responsibilities for:</td>
            </tr>
            <tr>
              <td class="clause-col">5.6</td>
              <td class="req-text">The assignment of responsibilities should consider the required experience and competency, the relevance of the role and the necessary access to information.</td>
            </tr>
            <tr>
              <td class="clause-col">5.6</td>
              <td class="req-text">The organization should ensure that the assignment of responsibilities takes into account the relevant need for a multidisciplinary approach to consider impacts that can be reasonably foreseen and addressed throughout the AI system&#x27;s life cycle.</td>
            </tr>
            <tr>
              <td class="clause-col">5.7</td>
              <td class="req-text">around AI system use, are documented. The organization should define those thresholds, based on the context in which they operate. This can include considerations such as:</td>
            </tr>
            <tr>
              <td class="clause-col">5.7</td>
              <td class="req-text">the organization should document what the next steps are as part of the overall process.</td>
            </tr>
            <tr>
              <td class="clause-col">5.7</td>
              <td class="req-text">The organization should also consider how overall impact scales are determined and reasonably foreseeable impacts are calculated. The results of an AI system impact assessment can indicate, for example, that intended uses for an AI system are not sensitive but can affect a large population of users, and that should</td>
            </tr>
            <tr>
              <td class="clause-col">5.7</td>
              <td class="req-text">intended uses for an AI system are not sensitive but can affect a large population of users, and that should</td>
            </tr>
            <tr>
              <td class="clause-col">5.7</td>
              <td class="req-text">The organization should consider the magnitude of reasonably foreseeable impacts when defining the various pieces of the AI system impact assessment. The organization should have criteria for the types of reasonably foreseeable impacts that can be an outcome of the AI system. For example, to assess the magnitude of reasonably foreseeable impacts, the AI system impact assessment can include criteria for rating impacts as severe if they can lead to high adverse consequences for the organization, for groups of individuals or to societies (see, for example, Section 3.2 of Reference [16]).</td>
            </tr>
            <tr>
              <td class="clause-col">5.7</td>
              <td class="req-text">various pieces of the AI system impact assessment. The organization should have criteria for the types of reasonably foreseeable impacts that can be an outcome of the AI system. For example, to assess the magnitude of reasonably foreseeable impacts, the AI system impact assessment can include criteria for rating impacts as severe if they can lead to high adverse consequences for the organization, for groups of individuals or to societies (see, for example, Section 3.2 of Reference [16]).</td>
            </tr>
            <tr>
              <td class="clause-col">5.8</td>
              <td class="req-text">In performing the AI system impact assessment, the organization should consider, as appropriate:</td>
            </tr>
            <tr>
              <td class="clause-col">5.8</td>
              <td class="req-text">impacts and harmful impacts should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">5.8</td>
              <td class="req-text">Inputs from diverse communities should be encouraged and integrated into the assessment as they can add varied perspectives.</td>
            </tr>
            <tr>
              <td class="clause-col">5.9</td>
              <td class="req-text">of AI systems. The assessment should be analysed and incorporated into both technical and management decisions.</td>
            </tr>
            <tr>
              <td class="clause-col">5.9</td>
              <td class="req-text">benefits and harm as detailed in 6.8.2. Additionally, the results of the assessment should be compared to the thresholds established in 5.7 and if the thresholds are not met, an action plan to remediate should be identified.</td>
            </tr>
            <tr>
              <td class="clause-col">5.9</td>
              <td class="req-text">the thresholds established in 5.7 and if the thresholds are not met, an action plan to remediate should be identified.</td>
            </tr>
            <tr>
              <td class="clause-col">5.10.1</td>
              <td class="req-text">5.10.1 The organization should define and document expectations for how the AI system impact assessment is to be recorded, as well as expectations for reporting the results of the AI system impact assessment and measures taken to address the identified impacts. The format of the assessment can depend on the needs of the organization, and can be captured in a document template, a system, or through any other method that enables recording and reporting.</td>
            </tr>
            <tr>
              <td class="clause-col">5.10.3</td>
              <td class="req-text">5.10.3 External reporting should be commensurate with who the relevant interest parties are, their expectations, the need for transparency, whilst ensuring that information is not inappropriately divulged from a security, privacy or confidentiality perspective. External reporting considerations can include reporting to:</td>
            </tr>
            <tr>
              <td class="clause-col">5.10.5</td>
              <td class="req-text">5.10.5 Reports should be structured and worded such that they can provide the information needed by relevant interested parties to assess where necessary the AI system&#x27;s compliance with legal requirements related to impact assessments. They should also be structured and worded in a way that, where certain portions are unavailable for intellectual property protection or security purposes, they remain comprehensible.</td>
            </tr>
            <tr>
              <td class="clause-col">5.10.5</td>
              <td class="req-text">related to impact assessments. They should also be structured and worded in a way that, where certain portions are unavailable for intellectual property protection or security purposes, they remain comprehensible.</td>
            </tr>
            <tr>
              <td class="clause-col">5.11</td>
              <td class="req-text">The organization should document any approvals required as part of the AI system impact assessment process. This can include approvals related to exceeding established thresholds (see 5.7) or a final approval of the overall AI system impact assessment. Considerations can include:</td>
            </tr>
            <tr>
              <td class="clause-col">5.12.1</td>
              <td class="req-text">5.12.1 The organization should define and document processes for monitoring and review of AI system impact assessments, including the following:</td>
            </tr>
            <tr>
              <td class="clause-col">5.12.2</td>
              <td class="req-text">5.12.2 The AI system assessment review output should include decisions related to:</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">organization should determine its needs based on its context and not all of the guidance in this clause is applicable to every organization. For example, it is possible that an organization implementing an AI system developed by a third-party does not have details on the data (6.4) or algorithm information (6.5).</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">The scope of the AI system impact assessment should describe the AI system under consideration, its foreseeable impacts, and internal and external influences that affect these impacts. The scope of the AI system impact assessment should describe the AI system with the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">system impact assessment should describe the AI system with the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">If relevant, the scope description should clearly indicate exceptions from the items listed in a) to d). The scope of the impact assessment can include or be complemented by other impact assessments (e.g.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">The AI system impact assessment should include a basic description of the AI system, describing what the AI system does and, at a high-level, how it works. The description should include what kind of capabilities the AI system has, to give potential reviewers the necessary context to understand the AI system and the environment in which it operates. The AI system description can include additional detail as determined by the organization, such as:</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">AI system does and, at a high-level, how it works. The description should include what kind of capabilities the AI system has, to give potential reviewers the necessary context to understand the AI system and the environment in which it operates. The AI system description can include additional detail as determined by the organization, such as:</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">The documentation on the AI system features should be a more specific and detailed description of the functionalities and capabilities, and whether they are current or planned. This can include a high-level description of, for example:</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">In the documentation of AI system functionalities and capabilities, the organization should identify and limit the disclosure of the technical details to specific groups of individuals to reduce the possibility of misuses.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">The purpose of the AI system should be documented to help potential reviewers understand why the organization is building or using the AI system and how the AI technology contributes to achieving these objectives. When documenting the purpose of the AI system, the organization should consider the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">objectives. When documenting the purpose of the AI system, the organization should consider the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">should identity and document intended uses, including beneficial uses.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.5.1</td>
              <td class="req-text">6.3.5.1 The organization should identify and document reasonably foreseeable misuses.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.5.2</td>
              <td class="req-text">should use methods as appropriate to:</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">is most comprehensive. The organization should consider this when determining what information to include in an AI system impact assessment.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">When documenting datasets used in AI systems in an AI system impact assessment, the organization should consider its data quality, data governance, security, and privacy processes in relation to such datasets. Such considerations should include the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">considerations should include the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">readable form, but it should also be usable by human reviewers.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">When documenting data quality in an AI system impact assessment, the organization should consider the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">The organization should document information around such algorithms and models, including on their development, to ensure that reasonably foreseeable impacts related to them can be considered and assessed.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5.5</td>
              <td class="req-text">When developing documentation for the algorithms used in an AI system, the organization should consider the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.5.5</td>
              <td class="req-text">should consider the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.5.5</td>
              <td class="req-text">When developing documentation for the models used in an AI system, the organization should consider the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.5.5</td>
              <td class="req-text">should be considered with the new data and scenarios applied. 6.5.5 Information on model development When developing the documentation of models in an AI system impact assessment, the organization should consider the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.5.5</td>
              <td class="req-text">When developing the documentation of models in an AI system impact assessment, the organization should consider the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.6</td>
              <td class="req-text">they are deployed, so should be a consideration when documenting AI system impact assessments. When documenting the impact of an AI system deployed in a particular country or region, the organization should consider:</td>
            </tr>
            <tr>
              <td class="clause-col">6.6</td>
              <td class="req-text">should consider:</td>
            </tr>
            <tr>
              <td class="clause-col">6.6</td>
              <td class="req-text">The organization should further document planned actions to be taken towards improvements of future releases of the AI systems with regard to geographical and cultural specifics or legal requirements of the country or region of deployment.</td>
            </tr>
            <tr>
              <td class="clause-col">6.6</td>
              <td class="req-text">languages, cultures or traits, the AI system should be trained, tested and validated using data representative of the locale(s) in which it will be deployed. If the AI system is pre-trained, the AI system should be thoroughly tested and validated using data representative of the locale(s) in which it will be deployed.</td>
            </tr>
            <tr>
              <td class="clause-col">6.6</td>
              <td class="req-text">of the locale(s) in which it will be deployed. If the AI system is pre-trained, the AI system should be thoroughly tested and validated using data representative of the locale(s) in which it will be deployed.</td>
            </tr>
            <tr>
              <td class="clause-col">6.6</td>
              <td class="req-text">should include information on the technical deployment environment and relevant constraints. These can include information such as:</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">In the process of documenting the impact assessment, the organization should consider the specific impact on individuals, group of individuals and societies, as well as the role and obligations to other interested parties.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">The organization should identify and document individuals, groups of individuals or societies that can be affected by an AI system and its intended use in the AI system impact assessment. Relevant interested parties include both those who interact directly with the AI system and those who can be impacted by it without necessarily interacting. Some examples of relevant interested parties include:</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">relevant interested parties, or the individuals and groups themselves, should be consulted during the AI system impact assessment process. The results of the consultations should be documented.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">system impact assessment process. The results of the consultations should be documented. Scale and scope of the consultation with relevant interested parties should be proportional to a result and estimated initial risk level from a triaging process commensurate with the scale and scope of the AI system impact assessment process (for example, if high-risk level estimate, then the AI system impact assessment as well as consultation process can be more robust). Regardless of the risk level, the consultation process can enable the organization to understand and respond to interests and concerns of relevant parties in</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">Scale and scope of the consultation with relevant interested parties should be proportional to a result and estimated initial risk level from a triaging process commensurate with the scale and scope of the AI system impact assessment process (for example, if high-risk level estimate, then the AI system impact assessment as well as consultation process can be more robust). Regardless of the risk level, the consultation process can enable the organization to understand and respond to interests and concerns of relevant parties in good faith. Consultation should provide timely and relevant information to such interested parties, include</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">good faith. Consultation should provide timely and relevant information to such interested parties, include diverse perspectives, taking due account to consider specific needs of vulnerable groups or individuals, and ensuring that affected relevant interested parties are free from retaliation and retribution, maintaining confidentiality and anonymity where necessary, and giving individuals the opportunity to challenge decisions and, where appropriate apply, for redress.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">The organization should consider where other interested parties should be identified and documented as part of the AI system impact assessment process. These interested parties are not necessarily impacted by the AI system but have a relationship to it that should be captured. Some examples include:</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">the AI system but have a relationship to it that should be captured. Some examples include:</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">should be identified. 6.8.2 Benefits and harms 6.8.2.1 General For each relevant interested party, the reasonably foreseeable benefits and harms should be analysed. For</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">For each relevant interested party, the reasonably foreseeable benefits and harms should be analysed. For example, the organization conducting the impact assessment should consider the reasonably foreseeable benefits each relevant interested party can expect as a result of interacting with the AI system. The subclauses in this clause can be used to consider reasonably foreseeable benefits and harms related to various objectives. These objectives are not exhaustive and other objectives can be considered. For more information see Annex C.</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">example, the organization conducting the impact assessment should consider the reasonably foreseeable benefits each relevant interested party can expect as a result of interacting with the AI system. The subclauses in this clause can be used to consider reasonably foreseeable benefits and harms related to various objectives. These objectives are not exhaustive and other objectives can be considered. For more information see Annex C.</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">For each identified relevant interested party, the organization should analyse reasonably foreseeable benefits and harms related to accountability as a result of using the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">For each identified relevant interested party, the organization should analyse the reasonably foreseeable benefits and harms related to transparency when the AI system is used.</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">For each identified relevant interested party, the organization should analyse the reasonably foreseeable benefits and harms related to the organizational objective of fairness that the AI systems used can have on individuals and societies.</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">For each identified relevant interested party, the organization should analyse the reasonably foreseeable benefits and harms related to privacy when the AI system is used. PII principals can be a relevant interested party.</td>
            </tr>
            <tr>
              <td class="clause-col">6.8</td>
              <td class="req-text">For each identified relevant interested party, the organization should analyse the reasonably foreseeable benefits and harms related to reliability when the AI system is used.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">For each identified relevant interested party, the organization should analyse the reasonably foreseeable benefits and harms related to safety when the AI system is used.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">For each identified relevant interested party, the organization should analyse the reasonably foreseeable benefits and harms related to explainability when the AI system is used.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The AI system impact assessment should consider the environmental impacts of an AI system, including, but not limited to:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">AI system impact assessment should consider:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The organization should document potential failures of the AI system. These can include potential types of accidental inputs to the AI system, as well as failures of particular AI system components or processes. These can also include human error, failures of hardware or software, and unintended interactions of systems or processes.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The organization should determine the impacts to identified relevant interested parties (see 6.7) as a result of failures of the AI system. The consequences and impact on specific groups of individuals or societies because of AI system failures should be documented.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">because of AI system failures should be documented.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The organization should document reasonably foreseeable misuse of the AI system. It can be useful to estimate benefits to malicious actors deliberately misusing the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The organization should determine and document the reasonably foreseeable impacts to identified interested parties (see 6.7) as a result of the typical reasonably foreseeable misuse of the AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.9</td>
              <td class="req-text">The organization should consider documenting both technical and management level measures to address harms and benefits within the AI system impact assessment, such as:</td>
            </tr>
            <tr>
              <td class="clause-col">6.9</td>
              <td class="req-text">a) Proposals for measures to be implemented on a technical level. Those proposals should be taken into account as part of AI system specific approval processes (see 5.11).</td>
            </tr>
            <tr>
              <td class="clause-col">6.9</td>
              <td class="req-text">These recommendations should be taken into account when preparing and updating the risk treatment plan.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">assessment should be docu- mented in the AI policy.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">ization should take the AI system impact assessment into account when assigning roles and responsibilities.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">zation should determine this for itself.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">AI system should be assessed throughout its life cycle.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">for AI systems. The organization should consider such guidance for each type of interested party relevant to the AI system that is subject to the AI system impact assessment.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">PII is used in systems that should not utilize it</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-11" data-shall="108" data-should="8">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-11')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">11</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC FDIS 42006</span>
        <span class="badge badge-fdis">FDIS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Audit/Certification of AIMS</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 108</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 8</span>
        <span id="arrow-TC-DOC-11" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-11" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Accountability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (108)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">In addition to the requirements of ISO/IEC 17021-1:2015, 5.2.5, certification bodies shall not provide consulting for management systems related to artificial intelligence, information security, data protection (e.g. in the form of an external data protection officer or data protection check) or risk management to their</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">body shall not perform at least the following:</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">The certification body shall not carry out any internal audits for the client to be certified. The restriction on conducting internal audits shall not be circumvented by renaming the activity as inspection, assessment or similar.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">conducting internal audits shall not be circumvented by renaming the activity as inspection, assessment or similar.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">In addition to the requirements of ISO/IEC 17021-1:2015, 5.3.1, certification bodies shall be able to demonstrate a contract with an insurance policy or an alternative mechanism. Either option shall provide an appropriate amount of cover (i.e. insured amount, limitation of liability) for personal injury, property damage and financial loss in proportion to the turnover (i.e. annual gross revenue) of the clients under audit or certification.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">demonstrate a contract with an insurance policy or an alternative mechanism. Either option shall provide an appropriate amount of cover (i.e. insured amount, limitation of liability) for personal injury, property damage and financial loss in proportion to the turnover (i.e. annual gross revenue) of the clients under audit or certification.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">and 7.1.3 shall apply. 7.1.2 Generic technical competence requirements The certification body shall define the competence requirements for each certification function as referenced in ISO/IEC 17021-1:2015, Table A.1. Basic knowledge of the client&#x27;s business and typical business processes knowledge is defined in ISO/IEC 17021-1:2015, Table A.1.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The certification body shall define the competence requirements for each certification function as referenced in ISO/IEC 17021-1:2015, Table A.1. Basic knowledge of the client&#x27;s business and typical business processes knowledge is defined in ISO/IEC 17021-1:2015, Table A.1.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">Table 1 specifies the additional knowledge and skills that a certification body shall define for the certification functions. &quot;X&quot; indicates that the certification body shall define the criteria and depth of knowledge and skills. The knowledge and skill requirements specified in Table 1 are explained in more detail in 7.1.3 and are cross-referenced in parentheses in Table 1.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">functions. &quot;X&quot; indicates that the certification body shall define the criteria and depth of knowledge and skills. The knowledge and skill requirements specified in Table 1 are explained in more detail in 7.1.3 and are cross-referenced in parentheses in Table 1.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">In addition to the technical knowledge requirements specified in Table 1, the certification body shall define criteria, including the knowledge and skills of the audit team that is necessary for the client organization and the technical area(s) regarding the scope of the client&#x27;s AIMS.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">document, a specific standard or certification scheme incorporating ISO/IEC 42001, these shall be applied.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The certification body shall have criteria for verifying the competence of audit team members that ensures that at least they have the skills to apply their knowledge of:</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The audit team members shall, collectively, have skills appropriate to the requirements above, which can be demonstrated through experience of their application.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">The audit team members shall, collectively, be competent in tracing and identifying indications of incidents with serious negative effects on affected persons in the client&#x27;s AIMS back to the appropriate elements of the AIMS.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">intelligence, but the audit team as a whole shall have appropriate competence to cover the AIMS scope being audited.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">certification body shall have knowledge of the requirements of 7.1.3.1.1. This also applies for the team of personnel handling appeals.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Each member of the audit team shall have knowledge of:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The audit team members shall, collectively, have knowledge of all controls contained in ISO/IEC 42001:2023, Annex A and their implementation.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Personnel reviewing audit reports and making certification decisions shall have knowledge of list items a) to d) in 7.1.3.2.1. This also applies for the team of personnel handling appeals.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">the needed audit competence and determining the audit time shall have knowledge of list items a) to d) in 7.1.3.2.1.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The certification body audit team shall have knowledge of the legal obligations that apply to artificial intelligence.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Personnel reviewing audit reports and making certification decisions shall have knowledge of 7.1.3.3.1. This also applies for the team of personnel handling appeals.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">needed audit competence and determining the audit time shall have knowledge of 7.1.3.3.1.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Each member of the audit team shall have knowledge of:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The audit team members shall, collectively, have knowledge of: e) risk management processes, including assessment and mitigation procedures (in particular knowledge of ISO/IEC 23894[6]);</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Personnel reviewing audit reports and making certification decisions shall have knowledge of the list items</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">the needed audit competence and determining the audit time shall have knowledge of list items a) to c) in 7.1.3.4.1.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Each member of the audit team shall have knowledge of:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The audit team members shall, collectively, have knowledge of: e) codes of conduct as well as good practices and procedures on trustworthy AI (e.g. related to</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Personnel reviewing audit reports and making certification decisions shall have knowledge of list items a) to f) in 7.1.3.5.1. This also applies for the team of personnel handling appeals.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">needed audit competence and determining the audit time shall have knowledge of list item a) in 7.1.3.5.1. 7.1.3.6 Client products, processes and organization 7.1.3.6.1 Auditing The audit team members shall, collectively, have knowledge of:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The audit team members shall, collectively, have knowledge of:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Personnel reviewing audit reports and making certification decisions shall have knowledge of list items a) to b) in 7.1.3.6.1. This also applies for the team of personnel handling appeals.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">The certification body shall demonstrate that each auditor has acquired knowledge and skills through each of:</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">In addition to 7.1.2 and 7.1.3, the process for selecting auditors shall ensure that each auditor:</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">systems (such as but not limited to ISO 9001,[13] ISO/IEC 27001[10]). This experience shall have been gained in at least ten audit days or of at least three management system audits (stage 1 and stage 2) as auditor or auditor in-training, and the experience shall be performed in the last five years. This experience shall have been gained as an auditor under the supervision and evaluation of a more experienced auditor (see ISO/IEC 17021-1:2015, 9.2.2.1.4) in the course of participation in at least one initial certification or re-certification audit and at least one surveillance audit. The participation shall</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">as auditor or auditor in-training, and the experience shall be performed in the last five years. This experience shall have been gained as an auditor under the supervision and evaluation of a more experienced auditor (see ISO/IEC 17021-1:2015, 9.2.2.1.4) in the course of participation in at least one initial certification or re-certification audit and at least one surveillance audit. The participation shall include review of documentation and risk assessment, implementation assessment, and audit reporting;</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">experience shall have been gained as an auditor under the supervision and evaluation of a more experienced auditor (see ISO/IEC 17021-1:2015, 9.2.2.1.4) in the course of participation in at least one initial certification or re-certification audit and at least one surveillance audit. The participation shall include review of documentation and risk assessment, implementation assessment, and audit reporting;</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">initial certification or re-certification audit and at least one surveillance audit. The participation shall include review of documentation and risk assessment, implementation assessment, and audit reporting;</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">In addition to 7.2.2.1 and 7.2.2.2, the criteria for selecting an auditor for leading the team shall ensure that the auditor has actively participated as auditor in all stages of at least three management system audits. The participation shall include initial scoping and planning, document review, review of risk assessment and its implementation, and formal audit reporting.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">participation shall include initial scoping and planning, document review, review of risk assessment and its implementation, and formal audit reporting.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">The audit team leader shall meet these requirements, through previous experience in supervised audits performed by an experienced AIMS auditor who has conducted at least three ISO/IEC 42001 audits.</td>
            </tr>
            <tr>
              <td class="clause-col">8.2</td>
              <td class="req-text">Certification documents shall be signed by the officer who has been assigned that responsibility and shall additionally to ISO/IEC 17021-1:2015, 8.2.2 entail the following:</td>
            </tr>
            <tr>
              <td class="clause-col">8.4</td>
              <td class="req-text">Prior to the certification audit, the certification body shall ask the client to report if any AIMS related information (such as AIMS records of information about design and effectiveness of controls or access to source code and raw data) cannot be made available for review by the audit team because it contains confidential or sensitive information. The certification body shall determine whether the AIMS can be adequately audited in the absence of such information. If the certification body concludes that it is not possible to adequately audit the AIMS without reviewing the identified confidential or sensitive information,</td>
            </tr>
            <tr>
              <td class="clause-col">8.4</td>
              <td class="req-text">confidential or sensitive information. The certification body shall determine whether the AIMS can be adequately audited in the absence of such information. If the certification body concludes that it is not possible to adequately audit the AIMS without reviewing the identified confidential or sensitive information, it shall advise the client that the certification audit cannot take place until appropriate access arrangements are granted.</td>
            </tr>
            <tr>
              <td class="clause-col">8.4</td>
              <td class="req-text">it shall advise the client that the certification audit cannot take place until appropriate access arrangements are granted.</td>
            </tr>
            <tr>
              <td class="clause-col">8.4</td>
              <td class="req-text">The certification body and the client shall mutually establish and implement safeguards for protected information or sensitive information, intellectual property, trade secrets and the technical means and infrastructures to be used in the certification agreement in accordance with ISO/IEC 17021-1:2015, 5.1.2.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">The audit programme shall cover all applicable management system requirements and shall identify the stakeholder role(s) of the client organization.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">The certification body shall ensure that the client&#x27;s definition of the certification scope includes all significant processes and risks relevant to the AI system and is reflected in the statement of applicability (SoA). The SoA defines the scope of certification.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">Certification bodies shall provide the audit team with sufficient time to perform all activities related to an initial certification audit, surveillance audit, or re-certification audit. The calculation of total audit time shall include sufficient time for audit reporting and for internal consultation within the audit team.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">initial certification audit, surveillance audit, or re-certification audit. The calculation of total audit time shall include sufficient time for audit reporting and for internal consultation within the audit team.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">Additional time shall be scheduled and provided as needed for each nonconformity finding, separate from normal audit time calculations, to evaluate corrective actions, if needed.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">The certification body shall use 9.1.4. and Annex A to determine audit time requirements for the defined scope under ISO/IEC 42001. The specified audit times in Annex A relate to the activities of the audit team and potential technical experts on site. The allocation of audit time within the audit team is permitted, but not the reduction of the total audit time according to the calculation.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">important to an AIMS shall appear clearly and be readily identifiable in the audit reports. The quality of the audit shall not be adversely affected by the combination of the audits.</td>
            </tr>
            <tr>
              <td class="clause-col">9.1</td>
              <td class="req-text">audit shall not be adversely affected by the combination of the audits.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">The audit objectives shall include:</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">The audit team shall audit the AIMS of the client covered by the defined certification scope against all applicable certification requirements. The certification body shall confirm, in the scope of the client&#x27;s AIMS, that the client addresses all requirements.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">applicable certification requirements. The certification body shall confirm, in the scope of the client&#x27;s AIMS, that the client addresses all requirements.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">Certification bodies shall ensure that the risk assessment and risk treatment of the client&#x27;s AI management system adequately reflects its activities and extends to the boundaries of the activities as defined in the scope of certification. Certification bodies shall confirm that this is reflected in the client&#x27;s scope of their AIMS and statement of applicability (SoA). The certification body shall verify that there is at least one SoA per scope of certification.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">scope of certification. Certification bodies shall confirm that this is reflected in the client&#x27;s scope of their AIMS and statement of applicability (SoA). The certification body shall verify that there is at least one SoA per scope of certification.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">AIMS and statement of applicability (SoA). The certification body shall verify that there is at least one SoA per scope of certification.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">Certification bodies shall ensure that interfaces to services or activities that are not entirely within the AIMS scope of applicability are addressed in the AIMS undergoing certification and have been included in the risk assessment of the client&#x27;s artificial intelligence management system. An example of such a situation is the sharing of facilities on which the AI system runs or is interconnected (e.g. IT systems, databases and telecommunication systems or the outsourcing of a business function) with other organizations.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">The criteria against which the AIMS is audited shall be the AIMS standard ISO/IEC 42001. Other documents can be required for certification relevant to the function of the AIMS performed. In this context, all processes for regional and regulatory specificities covered by the AIMS will be reviewed and assessed by the certification body for suitability in stage 1 to enable an appropriate and risk-based selection of audit evidence for stage 2. The audit criteria may be expanded to include comparison of controls additional to</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">Certification bodies intending to conduct remote audit activities shall define procedures to determine the level of remote audit activities (&quot;remote audits&quot;) that can be applied to auditing a client&#x27;s AIMS. The audit plan and audit report shall include clear indications if remote audit activities have been performed.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">plan and audit report shall include clear indications if remote audit activities have been performed. The procedures shall include analysis of the risks related to the use of remote auditing for the client, which shall consider the following factors:</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">The procedures shall include analysis of the risks related to the use of remote auditing for the client, which shall consider the following factors:</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">shall consider the following factors:</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">The analysis shall be performed prior to performing any remote audit. The analysis and the justification for use of remote audit during the certification cycle shall be documented.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">use of remote audit during the certification cycle shall be documented. Remote audits shall not be used if the risk assessment identifies unacceptable risks to the effectiveness of the audit process.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">Remote audits shall not be used if the risk assessment identifies unacceptable risks to the effectiveness of the audit process.</td>
            </tr>
            <tr>
              <td class="clause-col">9.2</td>
              <td class="req-text">The risk assessment shall be reviewed during the certification cycle to ensure its continued suitability.</td>
            </tr>
            <tr>
              <td class="clause-col">9.3</td>
              <td class="req-text">In this stage of the audit, the certification body shall obtain documentation on the design of the AIMS that covers the documentation required by ISO/IEC 42001.</td>
            </tr>
            <tr>
              <td class="clause-col">9.3</td>
              <td class="req-text">The certification body shall obtain a sufficient understanding of the design of the AIMS in the context of the client&#x27;s organization, risk assessment and management (including defined measures), AI policy, and information security policy and objectives, and in particular the client&#x27;s readiness for the audit. This will enable planning for stage 2.</td>
            </tr>
            <tr>
              <td class="clause-col">9.3</td>
              <td class="req-text">The results of stage 1 shall be documented in a written report. The certification body shall review the stage</td>
            </tr>
            <tr>
              <td class="clause-col">1</td>
              <td class="req-text">1 audit report before deciding on proceeding with stage 2. The certification body shall confirm that the</td>
            </tr>
            <tr>
              <td class="clause-col">1</td>
              <td class="req-text">The certification body shall make the client aware of the further types of information and records that can be required for detailed examination during stage 2.</td>
            </tr>
            <tr>
              <td class="clause-col">1</td>
              <td class="req-text">Based on the findings documented in the stage 1 audit report, the certification body shall develop an audit plan for the conduct of stage 2 according to the requirements of ISO/IEC 17021-1:2015, 9.3.1.3. In addition to evaluating the effective implementation of the AIMS, the objective of stage 2 is to confirm that the client adheres to its own policies, objectives and procedures.</td>
            </tr>
            <tr>
              <td class="clause-col">9.6</td>
              <td class="req-text">Surveillance audit procedures shall be consistent with those related to the certification audit of the client&#x27;s organization as outlined in this document.</td>
            </tr>
            <tr>
              <td class="clause-col">9.6</td>
              <td class="req-text">The certification body shall adapt its surveillance programme to address AI system issues related to risks and effects to the client and justify that programme.</td>
            </tr>
            <tr>
              <td class="clause-col">9.6</td>
              <td class="req-text">Surveillance audits may be combined with audits of other management systems. Reporting shall clearly identify the aspects relevant to each management system.</td>
            </tr>
            <tr>
              <td class="clause-col">9.6</td>
              <td class="req-text">As part of surveillance audits, certification bodies shall review records of appeals and complaints submitted to the certification body. In cases of identified nonconformities, certification bodies shall verify that the client has investigated its own AIMS and procedures and taken appropriate corrective action.</td>
            </tr>
            <tr>
              <td class="clause-col">9.6</td>
              <td class="req-text">to the certification body. In cases of identified nonconformities, certification bodies shall verify that the client has investigated its own AIMS and procedures and taken appropriate corrective action.</td>
            </tr>
            <tr>
              <td class="clause-col">9.6</td>
              <td class="req-text">A surveillance audit report shall include, in particular, information on the resolution of previously discovered nonconformities, as well as the version of the SoA and significant changes since the last audit.</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">Certification bodies shall allow auditors sufficient time to undertake all activities relating to an initial audit, surveillance audit or re-certification audit. The calculation of overall audit time shall include sufficient time for audit reporting.</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">surveillance audit or re-certification audit. The calculation of overall audit time shall include sufficient time for audit reporting.</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">The certification body shall identify the amount of audit time to be spent on initial certification, surveillance and re-certification for each client and certified AIMS. Using this Annex A at the audit-planning phase leads to a consistent approach to the determination of appropriate audit time. Additionally, the audit time can be adjusted based on what is found during the course of the audit, especially during stage 1 (e.g. different scopes and system impacts that affect the assessment of the complexity of the AIMS).</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">time for initial audit&quot;) below and shall consider contributing factors for modification. The approach for determining audit time defined by the certification body shall be regularly reviewed to verify if it is sufficient for the complexity of the AIMS and for the actual effects on individuals, groups of individuals and societies.</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">The approach for determining audit time defined by the certification body shall be regularly reviewed to verify if it is sufficient for the complexity of the AIMS and for the actual effects on individuals, groups of individuals and societies.</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">The certification body shall use the factors given in A.3 and further consider the activities of the client&#x27;s AIMS to determine audit time.</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">Coherent, consistent and repeatable procedure(s) that can be applied on a client-by-client basis shall be documented.</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">To determine sufficient time for performing audit activities, further factors shall be considered. Those factors depend on (external) factors such as but not limited to any applicable regulatory frameworks, the implementation of the managed AI systems within sensitive areas or third-party agreements relevant for AIMS.</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">The calculation of audit time shall follow a documented procedure.</td>
            </tr>
            <tr>
              <td class="clause-col">8</td>
              <td class="req-text">The time allocated shall also consider the following factors that relate to the complexity of a client&#x27;s AIMS and therefore to the effort needed to audit the organization:</td>
            </tr>
            <tr>
              <td class="clause-col">8</td>
              <td class="req-text">To determine the total audit time, all applicable factors for adjustment listed in a) to e) shall be applied for the specific AIMS.</td>
            </tr>
            <tr>
              <td class="clause-col">8</td>
              <td class="req-text">A.3.1 and A.3.2. Where additional time is required for planning and / or report writing, this shall not be a justification for reducing on-site audit time. Auditor travel time is not included in this calculation and is additional to the total audit time calculated in accordance with A.3.1 and A.3.2.</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">shall be increased to allow for the audit changes in the AIMS (such as but not limited to the audit of new or changed AIMS controls, processes and services).</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">In addition to the usual surveillance cycle, the certification body shall reach an agreement with its client to regulate additional surveillance of the client&#x27;s own monitoring activities, if the AIMS manages AI systems classified as high-risk or applied within sensitive purposes (e.g. health; safety critical; affecting personal rights; etc.). This can include additional audits or an agreement on the provision of parameters that can cause extraordinary surveillance measures by the certification body.</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">Parameters shall be set in a way that they indicate changes to certification-relevant criteria of the AI system monitored by the AIMS. In the event of a change indicated by those parameters for which the certified client takes measures, the certification body shall assess if additional surveillance measures for the AIMS of the client are necessary.</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">takes measures, the certification body shall assess if additional surveillance measures for the AIMS of the client are necessary.</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">The total amount of time spent performing the re-certification audit shall depend upon the results of any prior audit as defined in 9.6.3. The audit time for a re-certification should be proportional to, but at least two thirds of, the audit time required for an initial certification audit of the same organization at the time of the re-certification audit.</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">factors of audit time. Appropriate reasons for deviation shall be described and documented. A.7 Audit time of multi-site The requirements of ISO/IEC 17021-1:2015, 9.1.5 apply.</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">The audit time required to extend the scope of an AIMS shall be calculated based on the following factors:</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">The certification body shall have procedures that provides a consistent approach to extension of the scope. For the initial certification audit of the extended scope, the time shall be calculated based on the number of persons involved in the AI life cycle and the factors for adjustment of audit time, both being added to the already existing scope using A.3.1 and A.3.2.</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">For the initial certification audit of the extended scope, the time shall be calculated based on the number of persons involved in the AI life cycle and the factors for adjustment of audit time, both being added to the already existing scope using A.3.1 and A.3.2.</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">Audit time shall be added to the calculated duration to review the certified client running its AIMS. This additional time shall be at least:</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">additional time shall be at least:</td>
            </tr>
            <tr>
              <td class="clause-col">0</td>
              <td class="req-text">The certification documents for an AIMS shall demonstrate conformance with the content of the template in C.2. The certification body can display the information as it suits itself.</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (8)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">After the training, the trainee should be capable of applying and transforming their knowledge of</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">A basic assumption of this approach is that a calculation scheme for determining audit time should:</td>
            </tr>
            <tr>
              <td class="clause-col">10.3</td>
              <td class="req-text">activities should be identified in the audit plan (see 9.2.3) and may be considered as partially contributing to the total &quot;on-site audit time&quot;.</td>
            </tr>
            <tr>
              <td class="clause-col">8</td>
              <td class="req-text">It is expected that the time calculated for planning and report writing combined should not typically reduce the total on-site &quot;audit time&quot; (physical/remote) to less than 70 % of the time calculated in accordance with A.3.1 and A.3.2. Where additional time is required for planning and / or report writing, this shall not be a justification for reducing on-site audit time. Auditor travel time is not included in this calculation and is additional to the total audit time calculated in accordance with A.3.1 and A.3.2.</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">For the initial certification audit cycle, surveillance time for a given organization should be proportional to the time spent at initial certification audit with the total amount of time spent annually on surveillance being about 1/3 of the time spent on the initial certification audit. The planned surveillance time should be reviewed occasionally to account for changes that affect audit time. The time spent on a surveillance audit shall be increased to allow for the audit changes in the AIMS (such as but not limited to the audit of new or changed AIMS controls, processes and services).</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">being about 1/3 of the time spent on the initial certification audit. The planned surveillance time should be reviewed occasionally to account for changes that affect audit time. The time spent on a surveillance audit shall be increased to allow for the audit changes in the AIMS (such as but not limited to the audit of new or changed AIMS controls, processes and services).</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">prior audit as defined in 9.6.3. The audit time for a re-certification should be proportional to, but at least two thirds of, the audit time required for an initial certification audit of the same organization at the time of the re-certification audit.</td>
            </tr>
            <tr>
              <td class="clause-col">70</td>
              <td class="req-text">(including the applicable factors for adjustment of audit time) calculated in Table A.1 should be considered a minimum.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (3)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Accountability-002</code></td><td>Accountability</td><td>Level 2</td><td style="font-size:0.85em">[System] maintains complete audit trail for [decisions/actions] with [retention period] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Accountability-003</code></td><td>Accountability</td><td>Level 3</td><td style="font-size:0.85em">[System] undergoes annual independent accountability audit covering governance, traceability, and risk management per [s‚Ä¶</td></tr>
          <tr><td><code>SC-Security-002</code></td><td>Security</td><td>Level 3</td><td style="font-size:0.85em">[System] passes independent security audit with zero critical vulnerabilities per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-12" data-shall="0" data-should="103">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-12')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">12</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC 23894</span>
        <span class="badge badge-is">IS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Guidance on Risk Management</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 103</span>
        <span id="arrow-TC-DOC-12" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-12" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Accountability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Bias/Fairness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Risk ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Threat ‚¨Ü</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (103)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">4</td>
              <td class="req-text">Risk management should address the needs of the organization using an integrated, structured and comprehensive approach. Guiding principles allow an organization to identify priorities and make decisions on how to manage the effects of uncertainty on its objectives. These principles apply to all organizational levels and objectives, whether strategic or operational.</td>
            </tr>
            <tr>
              <td class="clause-col">4</td>
              <td class="req-text">in various environments, for specific use cases. Risk management should take into account the whole system, with all its technologies and functionalities, and its impact on the environment and stakeholders.</td>
            </tr>
            <tr>
              <td class="clause-col">4</td>
              <td class="req-text">Organizations should also be aware that the use of AI systems can introduce additional stakeholders.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">should be selected per stakeholders&#x27; needs. Stakeholders can help to identify the goals and describe the means for enhancing transparency and explainability of AI systems. In certain cases, these goals and means</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">ISO 31000:2018, organizations should estab lish organizational structures and measures to identify issues and opportunities related to emerging risks, trends, technologies, uses and actors related to AI systems.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">should be timely, clear and available to rel evant stakeholders.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">change quickly. Organizations should take this into account.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The internal use of AI systems should be considered, if any. Tracking the use of AI systems by customers and external users can be limited by intellectual property, contractual or market-specific restrictions.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Such restrictions should be captured in the AI risk management process and updated when business conditions warrant revisiting.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">any combination of these, should monitor the human and cultural landscape in which they are situated. Organizations should focus on identifying how AI systems or compo nents interact with pre-existing societal patterns that can lead to impacts on equitable</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">they are situated. Organizations should focus on identifying how AI systems or compo nents interact with pre-existing societal patterns that can lead to impacts on equitable outcomes, privacy, freedom of expression, fairness, safety, security, employment, the</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">risks related to the use of AI systems should be considered in the continual improvement process. Organizations engaged in the design, development or deployment of AI systems or system components, or any combination of these, should monitor the AI ecosystem for</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">these, should monitor the AI ecosystem for Performance successes, shortcomings and lessons learned, and maintain awareness of new AI research findings and techniques (opportunities for improvement).</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">top management should consider how policies and statements related to AI risks and risk management are communicated to stakeholders. Demonstrating this level of leadership and commitment can be critical for ensuring that stakeholders have confidence that AI is being developed and used responsibly.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">The organization should therefore consider issuing statements related to its commitment to AI risk management to increase confidence of their stakeholders on their use of AI.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">Top management should also be aware of the specialized resources that can be needed to manage AI risk, and allocate those resources appropriately.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">Organizations should consider at least the following elements of their external context:</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">Organizations should additionally consider, but not exclusively, the following elements:</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">should carefully consider the scope of relevant contracts.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">should be considered when provided by third parties.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">Organizations should consider at least the following elements of their external context:</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">Organizations should additionally consider, but not exclusively, the following elements:</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">Organizations should consider at least the follow ing elements of their internal context:</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">Organizations should additionally consider, but not exclu sively, the following elements:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Organizations should consider their own intellectual property in this area and ways that intellectual property can affect transparency, security and the ability to collaborate with stakeholders, to determine whether any steps should be taken.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">whether any steps should be taken.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Organizations should consider at least the follow ing elements of their internal context:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Organizations should additionally consider, but not exclu sively, the following elements:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">In addition to the guidance provided in ISO 31000:2018, 5.4.1, organizations should consider that the use of AI systems can increase the need for specialized training.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">applicable, should allocate resources and identify individuals:</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">Organizations should implement a risk-based approach to identifying, assessing, and understanding the AI risks to which they are exposed and take appropriate treatment measures according to the level of risk. The success of the overall AI risk management process of an organization relies on the identification, establishment and the successful implementation of narrowly scoped risk management processes on strategic, operational, programme and project levels. Due to concerns related but not limited to the potential complexity, lack of transparency and unpredictability of some AI-based</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">technologies, particular consideration should be given to risk management processes at the AI system project level. These system project level processes should be aligned with the organization&#x27;s objectives and should be both informed by and inform other levels of risk management. For example, escalations and lessons learned at the AI project level should be incorporated at the higher levels, such as the strategic, operational and programme levels, and others as applicable.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">project level. These system project level processes should be aligned with the organization&#x27;s objectives and should be both informed by and inform other levels of risk management. For example, escalations and lessons learned at the AI project level should be incorporated at the higher levels, such as the strategic, operational and programme levels, and others as applicable.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">and should be both informed by and inform other levels of risk management. For example, escalations and lessons learned at the AI project level should be incorporated at the higher levels, such as the strategic, operational and programme levels, and others as applicable.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">and lessons learned at the AI project level should be incorporated at the higher levels, such as the strategic, operational and programme levels, and others as applicable.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">the significance of risk to support decision-making processes should be extended to identify where AI</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">should be documented and included in the organization&#x27;s risk management process. 6.3.2 Defining the scope The guidance provided in ISO 31000:2018, 6.3.2 applies.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">The scope should take the specific tasks and responsibilities of the different levels of an organization into account. Moreover, the objectives and purpose of the AI systems developed or used by the organization should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">organization should be considered. 6.3.3 External and internal context The guidance provided in ISO 31000:2018, 6.3.3 applies.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">Because of the magnitude of potential effects of AI systems, the organization should pay special attention to the environment of its stakeholders when forming and establishing the context of the risk management process.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">Care should be taken to consider a list of stakeholders, including, but not limited to:</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">The guidelines in ISO 26000:2010[2] outlining aspects of social responsibility should apply as a framework for understanding and treating risk, particularly on core subjects of organizational governance, human rights, labour practices, the environment, fair operating practices, consumer issues and community involvement and development.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">‚Äî Organizations should take reasonable steps to understand uncertainty in all parts of the AI system, including the utilized data, software, mathematical models, physical extension, and human-in-the-loop aspects of the system (such as any related human activity during data collection</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">‚Äî Organizations should be aware that AI is a fast- moving technology domain. Measurement methods should be consistently evaluated according to their effectiveness and appropriateness for the AI systems in use.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">should be consistently evaluated according to their effectiveness and appropriateness for the AI systems in use.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">‚Äî Organizations should establish a consistent approach to determine the risk level. The approach should reflect the potential impact of AI systems regarding different AI-related objectives (see Annex A).</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">should reflect the potential impact of AI systems regarding different AI-related objectives (see Annex A).</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">and ability to mitigate realized AI risks should be considered when deciding its AI risk appetite.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">AI risks should be identified, quantified or qualitatively described and prioritized against risk criteria and objectives relevant to the organization. Annex B provides a sample catalogue of AI-related risk sources. Such a sample catalogue cannot be considered comprehensive. However, experience has shown the value of using such a catalogue as base for any organization performing a risk assessment exercise for the first time or integrating AI risk management into existing management structures. The catalogue serves as a documented baseline for these organizations.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">Organizations engaged in the development, provisioning or application of AI systems therefore should align their risk assessment activities with the system life cycle. Different methods for risk assessment can apply to different stages of the system life cycle.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">The organization should identify assets related to the design and use of AI that fall within the scope of the risk management process as defined in 6.3.2. Understanding what assets are within the scope and the relative criticality or value of those assets is integral to assessing the impact. Both the value of the asset and the nature of the asset (tangible or intangible) should be considered. Additionally, in relation</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">asset and the nature of the asset (tangible or intangible) should be considered. Additionally, in relation</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">to the development and use of AI, assets should be considered in the context of elements including but not limited to the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">The organization should identify a list of risk sources related to the development or use of AI, or both, within the defined scope.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">The organization should identify potential events that are related to the development or use of AI and can result in a variety of tangible or intangible consequences.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">The organization should identify controls relevant to either the development or use of AI, or both. Controls should be identified during the risk management activities and documented (in internal systems, procedures, audit reports, etc.).</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">Controls should be identified during the risk management activities and documented (in internal systems, procedures, audit reports, etc.).</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">The operating effectiveness of the identified controls should also be taken into account, particularly control failures.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">As part of AI risk assessment, the organization should identify risk sources, events or outcomes that can lead to risks. It should also identify any consequences to the organization itself, to individuals, communities, groups and societies. Organizations should take particular care to identify any differences between the groups who experience the benefits of the technology and the groups who experience negative consequences.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">can lead to risks. It should also identify any consequences to the organization itself, to individuals, communities, groups and societies. Organizations should take particular care to identify any differences between the groups who experience the benefits of the technology and the groups who experience negative consequences.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">communities, groups and societies. Organizations should take particular care to identify any differences between the groups who experience the benefits of the technology and the groups who experience negative consequences.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">The analysis approach should be consistent with the risk criteria developed as part of establishing the context (see 6.3).</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">When assessing the consequences identified in the risk assessment, the organization should distinguish between a business impact assessment, an impact assessment for individuals and a societal impact assessment.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Business impact analyses should determine the degree to which the organization is affected, and consider elements including but not limited to the following:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Impact analyses for individuals should determine the degree to which an individual can be affected by the development or use of AI by the organization, or both. They should consider elements including but not limited to the following:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">the development or use of AI by the organization, or both. They should consider elements including but not limited to the following:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Impact analyses for societies should determine the degree to which societies can be affected by the either development or use of AI by the organization, or both. They should consider elements including but not limited to the following:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">either development or use of AI by the organization, or both. They should consider elements including but not limited to the following:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Where applicable, the organization should assess the likelihood of occurrence of events and outcomes causing risks. Likelihood can be determined on a qualitative or quantitative scale and should align to the criteria established as part of 6.3.4. Likelihood can be informed and affected by (not limited to):</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">causing risks. Likelihood can be determined on a qualitative or quantitative scale and should align to the criteria established as part of 6.3.4. Likelihood can be informed and affected by (not limited to):</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Organizations should incorporate likelihood calculations only where they are applicable and useful for identifying where to apply risk treatments. There can be significant technical, economic and heuristic issues with decision-making based likelihoods, particularly when the likelihood either can&#x27;t be calculated or where the calculation has a large margin of error.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">Risk treatment options defined by the organization should be designed to reduce negative consequences of risks to an acceptable level, and to increase the likelihood that positive outcomes can be achieved. If the required reduction of negative outcomes cannot be achieved by applying different risk treatment options, the organization should carry out a risk-benefit analysis for the residual risks.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">options, the organization should carry out a risk-benefit analysis for the residual risks. In accordance with ISO 31000:2018, 6.5.2 the organization should consider:</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">In accordance with ISO 31000:2018, 6.5.2 the organization should consider:</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">should be implemented. The implementation of each risk treatment measure and its effectiveness should be verified and recorded according to 6.7.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">The implementation of each risk treatment measure and its effectiveness should be verified and recorded according to 6.7.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">The organization should establish, record, and maintain a system for the collection and verification of information on the product or similar products from the implementation and post-implementation phases. The organization should also collect and review publicly available information on similar systems on the market.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">phases. The organization should also collect and review publicly available information on similar systems on the market.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">This information should then be assessed for possible relevance on the trustworthiness of the AI system. In particular, the evaluation should assess whether previously undetected risks exist or previously assessed risks are no longer acceptable. This information can be fed and factored into the organization&#x27;s AI risk management process as adjustment of objectives, use cases or lessons learned.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">system. In particular, the evaluation should assess whether previously undetected risks exist or previously assessed risks are no longer acceptable. This information can be fed and factored into the organization&#x27;s AI risk management process as adjustment of objectives, use cases or lessons learned.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">If any of these conditions apply, organizations should perform the following:</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">should be evaluated. The results of this assessment should be recorded. The risk management record should allow the traceability of each identified risk through all risk management processes. The records can leverage a common template that is agreed upon by the organization.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">The results of this assessment should be recorded. The risk management record should allow the traceability of each identified risk through all risk management processes. The records can leverage a common template that is agreed upon by the organization.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">and risk treatment (see 6.5), the record should include at least the following information:</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">When identifying risks of AI systems, various AI-related objectives should be taken into account, depending on the nature of the system under consideration and its application context. AI-related objectives to consider include but are not limited to the objectives described in Clauses A.2 to A.12.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">Developers and users of AI systems should be aware of the related legislation in the countries where the system is brought onto the market and used.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">systems is needed. Organizations should ensure that people with such expertise are engaged in the development and specification of AI systems.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">Expertise of AI should extend to the end users of AI systems. Users should have sufficient understanding of how the AI system functions and are empowered to detect and override erroneous decisions or outputs.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">production data should be fit to the intended behaviour with respect to data type and quality. Training and test data should be validated for their currency and relevance for the intended purpose.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">Training and test data should be validated for their currency and relevance for the intended purpose. The amount of training and test data required can vary based on the intended functionality and complexity of the environment. The training and test data should have sufficiently diverse features in order to provide strong predictive power for the AI system. Furthermore, consistency should be ensured across training and test data, while using independent datasets when applicable.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">complexity of the environment. The training and test data should have sufficiently diverse features in order to provide strong predictive power for the AI system. Furthermore, consistency should be ensured across training and test data, while using independent datasets when applicable.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">in order to provide strong predictive power for the AI system. Furthermore, consistency should be ensured across training and test data, while using independent datasets when applicable.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">quality should be ensured also in that case.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">can consume substantial amounts of electrical power. These impacts on the environment should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">and do not follow a rule-based approach, the maintainability of an AI system and its implications should be investigated.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7</td>
              <td class="req-text">Consideration should be taken to determine if an AI system can infer sensitive personal data. For AI systems, protecting privacy includes protecting the data used for building and operating the AI system, ensuring that the AI system cannot be used to give unwarranted access to its data, and protecting access to models personalized for an individual or that can be used to infer information or characteristics of similar individuals.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">on ethic principles in terms of respect of human values, and human dignity should also be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">correctly in the presence of invalid inputs or stressful environmental conditions should be taken into consideration as well as the ability to reproduce measures and results.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">the design of machinery, transport, medical devices) should be taken into account for AI systems in these domains.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">poisoning, adversarial attacks and model stealing as described in ISO/IEC TR 24028:2020[3] should be considered beyond classical information and system security concerns.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">When identifying risks of AI systems, various risks sources should be taken into account depending on the nature of the system under consideration and its application context. Risk sources to consider include but are not limited to the issues and opportunities described in Clauses B.2 to B.8.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">consideration should be given to determining the degree to which the AI system environment is understood:</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">of uncertainty, which is a source of risk, and should be taken into account when designing such systems.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (4)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Accountability-001</code></td><td>Accountability</td><td>Level 1</td><td style="font-size:0.85em">[System] has defined accountability structure with assigned roles and governance documentation per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Safety-001</code></td><td>Safety</td><td>Level 2</td><td style="font-size:0.85em">[System] implements safety architecture Class [I/II/III] with [mechanism] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Safety-003</code></td><td>Safety</td><td>Level 1</td><td style="font-size:0.85em">[System] has documented safety risk management covering identified hazards per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Security-001</code></td><td>Security</td><td>Level 2</td><td style="font-size:0.85em">[System] implements security controls against [attack types] with documented threat model per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-13" data-shall="16" data-should="31">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-13')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">13</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC 24029-2</span>
        <span class="badge badge-is">IS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Robustness of Neural Networks</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 16</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 31</span>
        <span id="arrow-TC-DOC-13" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-13" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Explainability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Functional Correctness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (16)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">A domain shall be determined by a set of attributes which are clearly defined (i.e. the domain contains bounded objects).</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">In order to prove that a neural network remains performant in the presence of noisy inputs, a stability property shall be expressed.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">A stability criterion shall define at least the domain value space and output value space on which it has been measured and the stability property expected.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">For a comparison to be accurate, the following requirements shall be met: the neural networks perform the same task; the stability criterion is used on the same domain; the stability criterion proves the same objective.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">When a sensitivity analysis is used to determine whether a neural network stays bounded, the sensitivity analysis shall be used over a domain.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">A sensitivity criterion shall define at least the domain on which it has been measured and what are the sensitivity thresholds to be checked.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">For a comparison to be accurate, the following requirements shall be met: the neural networks shall perform the same task; the sensitivity criterion shall be used on the same domain; the sensitivity criterion shall prove the same objective.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">For a comparison to be accurate, the following requirements shall be met: the neural networks shall perform the same task; the relevance criterion shall be used on the same domain; the relevance criterion shall prove the same objective.</td>
            </tr>
            <tr>
              <td class="clause-col">5.6</td>
              <td class="req-text">A reachability property can specify either a set of failure states that the AI agent shall avoid or a set of goal states that the AI agent shall reach.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">For model checking to be valid, all models shall be checked.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">To do so, the sensitivity analysis shall utilize domains built around data points in the test data.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">Input domains are defined by attributes that define the space to be validated, with variation of those attributes that shall be explicitly bounded.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">The process to generate a perturbed input shall be explained when its setup varies from one person to another.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">This function shall rely on at least one bounded parameter.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">A minimum and a maximum variation shall be set on the corresponding parameters.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">One or more criterion (see Clause 5) shall be expressed on the domain.</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (31)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">The attributes should be bounded in the robustness specification.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">A stability property should be used on domains of uses which, in terms of expected behaviour, present some regularity properties.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">A stability property should not be used on a chaotic system as it is not relevant.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">A method for resolving conflicting results should be included in the comparison protocol.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">A relevance property should be used in cases where the neural network performs a task that can be done by a human.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">For these cases, the justification of the output of the neural network should be understood and verified.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">A relevance criterion should present the domain on which it has been measured and the expected results.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">If the expected results cannot be defined a priori, the relevance criterion should present at least the methodology to evaluate the results.</td>
            </tr>
            <tr>
              <td class="clause-col">5.6</td>
              <td class="req-text">A reachability criterion should be satisfied for a given set of initial states.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">In order to identify some of the learned features, the AI designer should use a relevance criterion.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">In case of an automatic confirmation, the evaluation should rely on a clear relevance target on the data.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">An explicit method should be defined in order to measure the level of correspondence between the relevance measured on any data and the relevance target.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">A threshold should be set in order to check if the level of correspondence is high enough.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">The relevance target should be provided.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">The spread of values of the attributes should be increased gradually in order to measure what classes are starting to overlap with each other.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">Any such partitioning of the input domain should be justified.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">In particular, the justification should highlight why the selected criterion is able to assess the robustness on this particular partitioning of the input domain.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">Then, a formal method should be used to evaluate the criteria on the represented domain with a variety of admissible perturbations.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4</td>
              <td class="req-text">These issues should be considered when integrating a neural network on a system on which one or more of these sources of numerical issues can occur.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4</td>
              <td class="req-text">In particular, formal methods should be used to check their impact.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">Domains that are sets of attributes that vary slowly (stable or quasi-stable domain) are domains on which robustness should be checked.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2</td>
              <td class="req-text">The choice of the attributes should depend on the application domain.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">A stability measurement function should be defined.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">One or more sensitivity measurement functions should be defined.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">One or more relevance measurement functions should be defined.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">When a formal method is used, the veracity of the logical model should be validated separately from the properties it is used to verify.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">When using a relevance analysis on neural networks, the sensitivity analysis should be used on the training data.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">Domain perturbation should be used when there is a specific domain in mind.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">The specification of the domain should be provided.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4</td>
              <td class="req-text">Numerical stability analysis should be carried out before verifying robustness properties of the neural network.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4</td>
              <td class="req-text">The report should state clearly the computational environment in which the neural network is deployed.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (2)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Robustness-001</code></td><td>Robustness</td><td>Level 2</td><td style="font-size:0.85em">[System] maintains performance degradation &lt; [X]% under [perturbation type] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Robustness-002</code></td><td>Robustness</td><td>Level 3</td><td style="font-size:0.85em">[System] passes formal robustness verification for [domain] with confidence interval [CI] per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-14" data-shall="0" data-should="0">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-14')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">14</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC TR 24027</span>
        <span class="badge badge-tr">TR</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Bias in AI Systems</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 0</span>
        <span id="arrow-TC-DOC-14" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-14" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Bias/Fairness</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHOULD statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (1)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Bias-Fairness-001</code></td><td>Bias/Fairness</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves demographic parity gap &lt; [X]% across [protected attributes] per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-15" data-shall="1" data-should="1">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-15')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">15</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC TR 24028</span>
        <span class="badge badge-tr">TR</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Trustworthiness in AI</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 1</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 1</span>
        <span id="arrow-TC-DOC-15" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-15" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Security</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Risk ‚¨Ü</span> <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Threat ‚¨Ü</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (1)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">irreversible harm, lack of full scientific certainty shall not be used as a reason for postponing effective measures to prevent harm. In safety engineering, a process for capturing and then sizing, stakeholder &quot;value&quot; requirements includes the understanding of the system&#x27;s context of use, the risks of harm and, when applicable, an application of the &quot;precautionary principle&quot; as a risk mitigation technique against potential unintended consequences, such as harm to rights and freedom of natural persons, life of any kind, the environment, a species or a community.</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (1)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">of residual risk. However, the risk associated with those hazards should be reduced to a tolerable level. Safety is achieved by reducing risk to a tolerable level which is defined in this Guide as tolerable risk.&quot; AI systems, which provided a certain level of autonomy, are often seen as more safety critical. However, the hazards and risks are application-dependent and not necessarily directly related to the level of autonomy (e.g. autonomous road vehicle vs. autonomous household vacuum cleaner).</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (8)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Trustworthiness-001</code></td><td>Trustworthiness</td><td>Level 1</td><td style="font-size:0.85em">[System] demonstrates trustworthiness through documented risk management and stakeholder engagement per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Trustworthiness-002</code></td><td>Trustworthiness</td><td>Level 2</td><td style="font-size:0.85em">[System] achieves trustworthiness score ‚â• [threshold] across [N] evaluated characteristics per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Trustworthiness-003</code></td><td>Trustworthiness</td><td>Level 3</td><td style="font-size:0.85em">[System] satisfies all normative trustworthiness requirements of [standard] as verified by accredited third party‚Ä¶</td></tr>
          <tr><td><code>SC-Transparency-001</code></td><td>Transparency</td><td>Level 1</td><td style="font-size:0.85em">[System] provides transparency documentation covering [aspects] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Security-001</code></td><td>Security</td><td>Level 2</td><td style="font-size:0.85em">[System] implements security controls against [attack types] with documented threat model per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Explainability-001</code></td><td>Explainability</td><td>Level 2</td><td style="font-size:0.85em">[System] provides [explanation type] explanations achieving faithfulness score ‚â• [X]% per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Availability-002</code></td><td>Availability</td><td>Level 2</td><td style="font-size:0.85em">[System] implements fault-tolerant architecture with documented backup/recovery procedure per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Resilience-001</code></td><td>Resilience</td><td>Level 2</td><td style="font-size:0.85em">[System] demonstrates graceful degradation with performance ‚â• [X]% under [failure condition] per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-16" data-shall="0" data-should="1">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-16')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">16</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC TR 24029-1</span>
        <span class="badge badge-tr">TR</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Robustness Part 1</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 1</span>
        <span id="arrow-TC-DOC-16" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-16" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (1)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">7.4</td>
              <td class="req-text">robustness goal. Benchmarking results should be interpreted with care[53].</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (2)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Robustness-001</code></td><td>Robustness</td><td>Level 2</td><td style="font-size:0.85em">[System] maintains performance degradation &lt; [X]% under [perturbation type] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Robustness-003</code></td><td>Robustness</td><td>Level 1</td><td style="font-size:0.85em">[System] has documented robustness evaluation methodology covering [perturbation types] per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-17" data-shall="0" data-should="6">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-17')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">17</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC TR 24368</span>
        <span class="badge badge-tr">TR</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Ethics and Society</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 6</span>
        <span id="arrow-TC-DOC-17" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-17" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Accountability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Bias/Fairness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Security</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (6)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">&quot;Applying a principle of explicability to AI research in Africa: should we do it?&quot;[53] argues that &quot;Given that values vary across cultures, an additional ethical challenge is to ensure that these AI systems are not developed according to some unquestioned but questionable assumption of universal norms but are in fact compatible with the societies in which they operate. This is particularly pertinent for AI research and implementation across Africa, a ground where AI systems are and will be used but also a place with a history of imposition of outside values.&quot; Explicability can assist to &quot;contribute to responsible and</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Bias due to poor representation, job losses, the application of AI in general, what lives AI should improve, what actions AI should be allowed to take, open data access to especially African data are presented as of specific concern to African communities. In addition to covering Ethics in AI in the African setting,</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">what actions AI should be allowed to take, open data access to especially African data are presented as of specific concern to African communities. In addition to covering Ethics in AI in the African setting,</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">Expert Group on How AI Principles Should be Implemented - AI Governance Guidelines working group[70] Japan has published the document called &quot;Social Principles of Human-centric AI&quot; adopted by the Integrated Innovation Strategy Promotion Council, which contributes to the formulation of the OECD&#x27;s recommendations on Artificial Intelligence. The social principles for AI are comprised of seven principles: (1) Human-centric, (2) Education/Literacy, (3) Privacy Protection, (4) Ensuring Security, (5) Fair Competition, (6) Fairness, Accountability, and Transparency, and (7) Innovation. The</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">principles of the first edition: Decisions made by AI should be explainable, transparent and fair and AI systems should be human-centric. The second edition includes additional considerations (such as robustness and reproducibility) and refines the original Model Framework for greater relevance and usability. For instance, the section on customer relationship management has been expanded to include considerations on interactions and communications with a broader network of stakeholders. The second edition of the Model Framework continues to take a sector- and technology-agnostic approach</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">AI systems should be human-centric. The second edition includes additional considerations (such as robustness and reproducibility) and refines the original Model Framework for greater relevance and usability. For instance, the section on customer relationship management has been expanded to include considerations on interactions and communications with a broader network of stakeholders. The second edition of the Model Framework continues to take a sector- and technology-agnostic approach that can complement sector-specific requirements and guidelines. The practical guidance concerns:</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (4)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Accountability-001</code></td><td>Accountability</td><td>Level 1</td><td style="font-size:0.85em">[System] has defined accountability structure with assigned roles and governance documentation per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Accountability-002</code></td><td>Accountability</td><td>Level 2</td><td style="font-size:0.85em">[System] maintains complete audit trail for [decisions/actions] with [retention period] per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Intervenability-001</code></td><td>Intervenability</td><td>Level 2</td><td style="font-size:0.85em">[System] implements human-in-the-loop review for [decision types] with documented intervention procedure per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Intervenability-002</code></td><td>Intervenability</td><td>Level 1</td><td style="font-size:0.85em">[System] provides appeal/redress mechanism for affected individuals per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-18" data-shall="0" data-should="43">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-18')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">18</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC TR 29119-11</span>
        <span class="badge badge-tr">TR</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">AI System Testing Guidelines</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 43</span>
        <span id="arrow-TC-DOC-18" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-18" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Functional Correctness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (43)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">autonomous cars). The &#x27;decision-making&#x27; function decides what the system&#x27;s next move should be (e.g. braking, turning, climbing, descending) depending on the function provided by the autonomous system (e.g. adaptive cruise control). The &#x27;control&#x27; function implements the decision by calling on actuators (e.g. to release air, open fuel valve).</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">suggests that different processors for each activity should be considered.</td>
            </tr>
            <tr>
              <td class="clause-col">3</td>
              <td class="req-text">systems that are non-deterministic (which is many of them) should not be used for higher-integrity systems, although in practice this often means that AI-based systems are considered as special cases and follow &#x27;tailored&#x27; versions of these standards, ignoring some of the requirements. These existing safety-related standards also require that the tools used to develop safety-related systems be suitably qualified. The currently available AI frameworks and algorithms are not qualified for use on the development of safety-related systems. Although it is possible to gain this qualification through use, the</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">should be followed.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">dangerous (e.g. pushing the boundaries of a flight envelope) and systems should exhibit caution when exploring in safety-related situations.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">Flexibility and adaptability requirements should specify those environment changes to which the system should be able to respond and also include requirements on the response process itself, such as maximum time to change, where appropriate. However, these requirements are likely to become less specific for systems where all possible future contexts of use have not been defined in detail.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">system should be able to respond and also include requirements on the response process itself, such as maximum time to change, where appropriate. However, these requirements are likely to become less specific for systems where all possible future contexts of use have not been defined in detail.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">expected level of human intervention should be specified for the system ‚Äì and so should be part of the system&#x27;s functional requirements (e.g. &#x27;the system will maintain cruise condition until one of the following occurs‚Ä¶&#x27;). Autonomy can also be considered in combination with adaptability or flexibility (e.g. system should be able to maintain a given level of adaptability or flexibility without human intervention). In some circumstances, an AI-based system may exhibit too much autonomy, in which case it may be necessary for a human to take control away from it.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">(e.g. system should be able to maintain a given level of adaptability or flexibility without human intervention). In some circumstances, an AI-based system may exhibit too much autonomy, in which case it may be necessary for a human to take control away from it.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">it soon becomes impracticable to explicitly specify how the robot should interact with every aspect of its operational environment. For instance, your cleaning robot would also have to be told that using a high-pressure hose to clean the kitchen was not practical due to the (side-) effect of the water on the electrical appliances and sockets.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">floor should eventually be clean (although unnecessary energy will have been expended), but there are many examples of reward hacking where the AI-based system satisfies the reward function but does not come close to achieving the required objective (e.g. a cleaning robot with a reward function based on it being able to see less visible dirt that disables its vision system).</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">AI-based systems is that they should be able to come up with smart ways to solve problems, often in ways humans would not have considered (or perhaps even understand).</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">of ethics and how AI-based systems should implement them is probably the most discussed topic in AI, drawing in far more people than those involved in the technical aspects of AI.</td>
            </tr>
            <tr>
              <td class="clause-col">40</td>
              <td class="req-text">The (ongoing) study has found that there is a broad consensus that systems should give priority to younger people, priority to people over animals and priority to saving more people (e.g. save four occupants of a car over two pedestrians). The study also found that there are significant differences in the choices made by people from different parts of the world (suggesting that autonomous cars may need to follow different ethical guidelines depending on where they are to be used).</td>
            </tr>
            <tr>
              <td class="clause-col">40</td>
              <td class="req-text">should be respected in the development, deployment and use of AI systems:</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">The specifications for ML models should contain a set of required performance metrics (see A.8) to act as acceptance criteria for the ML models. Acceptance criteria including metrics may consider false positives and negatives, recognizing that 100 % accuracy is unlikely to be achieved in many use cases.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">and non-functional requirements should be tested, and a form of regression testing, ideally automated, is often a suitable approach. The change process performed by the system should also be tested, to determine, for instance, whether the system can change within a required timeframe and whether the system stays within constraints for the resources consumed to achieve the change.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">is often a suitable approach. The change process performed by the system should also be tested, to determine, for instance, whether the system can change within a required timeframe and whether the system stays within constraints for the resources consumed to achieve the change.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">into thinking it is in control when it should request intervention (e.g. by creating test scenarios at the boundary of its operational envelope ‚Äì suggesting the application of boundary value concepts to scenario testing).</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">V, iterative) as these test levels should normally apply irrespective of the life cycle used. As with all testing, the selection of testing at different levels should be based on the perceived risks and the costs of testing. Typically, testing at earlier test levels (e.g. unit and integration testing) will be cheaper and</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">testing, the selection of testing at different levels should be based on the perceived risks and the costs of testing. Typically, testing at earlier test levels (e.g. unit and integration testing) will be cheaper and</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">risks that can be addressed at these levels should be tested as early as possible, however, some risks (e.g. based on the characteristics of a complete system) can only be addressed by testing a complete system and so will need to be addressed at the system test level (e.g. end-to-end scenario testing).</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Unit/component testing for non-AI components (e.g. user interface code) should be treated the same as for traditional systems.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Integration testing should be performed to ensure the AI component is correctly integrated with the remainder of the AI-based system of which it is a part (e.g. checking interfaces and that communicated data is correctly interpreted). For instance, tests should be performed to check that the correct image file is passed to the model for object recognition and that it is in the format expected by the model. Tests should also be performed to check that the output of the model is correctly interpreted and used by the rest of the system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">data is correctly interpreted). For instance, tests should be performed to check that the correct image file is passed to the model for object recognition and that it is in the format expected by the model. Tests should also be performed to check that the output of the model is correctly interpreted and used by the rest of the system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">should also be performed to check that the output of the model is correctly interpreted and used by the rest of the system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Business acceptance criteria should be tested as part of acceptance testing. These criteria will typically be focused on whether the AI-based system meets high-level business goals, such as those based on making or saving money, rather than on technical criteria, such as accuracy of results from a model.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Care should be taken when testing operational self-learning systems to ensure that tests do not cause the system to perform unwanted learning from the testing.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">The ML workflow that is used should be documented and followed when performing ML. Deviations from the workflow described in Annex A should be justified.</td>
            </tr>
            <tr>
              <td class="clause-col">7.2</td>
              <td class="req-text">from the workflow described in Annex A should be justified.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">Acceptance criteria (including both functional and non-functional requirements) should be documented and justified for use on this application. Performance metrics should be included for the model. As a minimum the AI-specific characteristics (described in 5.1) should be considered and could be used as the basis of a checklist used to determine the completeness of acceptance criteria for the AI-based system.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">and justified for use on this application. Performance metrics should be included for the model. As a minimum the AI-specific characteristics (described in 5.1) should be considered and could be used as the basis of a checklist used to determine the completeness of acceptance criteria for the AI-based system.</td>
            </tr>
            <tr>
              <td class="clause-col">7.3</td>
              <td class="req-text">minimum the AI-specific characteristics (described in 5.1) should be considered and could be used as the basis of a checklist used to determine the completeness of acceptance criteria for the AI-based system.</td>
            </tr>
            <tr>
              <td class="clause-col">7.4</td>
              <td class="req-text">The choice of framework, algorithm, model, settings and hyperparameters should be documented and justified.</td>
            </tr>
            <tr>
              <td class="clause-col">7.5</td>
              <td class="req-text">Boundary conditions are known to cause failures in all types of system (AI and non-AI) and should be included in the training data. The selection of training data in terms of the size of the dataset and characteristics such as bias, transparency and completeness should be documented and justified and confirmed by experts where the level of risk associated with the system warrants it (e.g. for critical systems).</td>
            </tr>
            <tr>
              <td class="clause-col">7.5</td>
              <td class="req-text">characteristics such as bias, transparency and completeness should be documented and justified and confirmed by experts where the level of risk associated with the system warrants it (e.g. for critical systems).</td>
            </tr>
            <tr>
              <td class="clause-col">7.6</td>
              <td class="req-text">be as independent of the training data as possible. The level of independence should be documented and justified. Test data should be systematically selected and/or created and should also include negative tests (e.g. inputs outside the expected input range) and adversarial tests (see 7.8 for details).</td>
            </tr>
            <tr>
              <td class="clause-col">7.6</td>
              <td class="req-text">justified. Test data should be systematically selected and/or created and should also include negative tests (e.g. inputs outside the expected input range) and adversarial tests (see 7.8 for details).</td>
            </tr>
            <tr>
              <td class="clause-col">7.7</td>
              <td class="req-text">Whenever the deployed model is updated it should be re-tested to ensure it continues to satisfy the acceptance criteria, including tests against implicit requirements that may not be documented, such as testing for model degradation (e.g. the new model runs slower than the previous model). Where appropriate, A/B testing or back-to-back testing should be performed against the previous model.</td>
            </tr>
            <tr>
              <td class="clause-col">7.7</td>
              <td class="req-text">appropriate, A/B testing or back-to-back testing should be performed against the previous model.</td>
            </tr>
            <tr>
              <td class="clause-col">8.1</td>
              <td class="req-text">should be considered at varying levels of effectiveness (e.g. the input from a video camera will degrade as a journey progress and it gets dirtier or the accuracy of a GPS unit will change as different numbers of satellites come into and go out of line of sight). Research is currently unclear on the necessary level of rigour that would be required for the use of combinatorial testing with safety-critical AI-based systems such as self-driving cars (e.g. pairwise may not be sufficient), but it is known that the approach is effective at finding defects and can also be used to estimate the residual level of risk.</td>
            </tr>
            <tr>
              <td class="clause-col">8.2</td>
              <td class="req-text">AI, software). A known problem with the use of pseudo-oracles is that for them to work well they should be completely independent of the software under test. With so much reusable, open source software being used to develop AI-based systems, this independence can be easily compromised.</td>
            </tr>
            <tr>
              <td class="clause-col">8.4</td>
              <td class="req-text">test cases are provided, then it should be possible to automate the generation of follow-up test cases, although it is not possible to automate the generation of the metamorphic relations, which requires some domain knowledge.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (2)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Functional_Correctness-001</code></td><td>Functional Correctness</td><td>Level 3</td><td style="font-size:0.85em">[System] achieves [metric] ‚â• [X]% on [benchmark] with acceptance criteria documented per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Resilience-003</code></td><td>Resilience</td><td>Level 1</td><td style="font-size:0.85em">[System] implements continuous drift monitoring with documented response procedure per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
  <div class="req-accordion" id="acc-TC-DOC-19" data-shall="0" data-should="1">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-19')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">19</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC TS 5723</span>
        <span class="badge badge-ts">TS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Trustworthiness Vocabulary</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 1</span>
        <span id="arrow-TC-DOC-19" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-19" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Accountability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Availability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Controllability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Reliability</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Resilience</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Robustness</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Safety</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Security</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span></div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (1)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">3.2.13 [NOTE]</td>
              <td class="req-text">The time interval duration can be expressed in units appropriate to the item concerned (e.g. calendar time, operating cycles, distance run, etc.) and the units should always be clearly stated.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
      <div class="req-type-section">
        <h4 style="color:#27ae60;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims;border-left:3px solid #27ae60;padding-left:8px;margin:16px 0 8px">Associated Simple Claims (2)</h4>
        <table class="req-table">
          <thead><tr><th>Claim ID</th><th>Characteristic</th><th>Level</th><th>Template</th></tr></thead>
          <tbody>
          <tr><td><code>SC-Trustworthiness-001</code></td><td>Trustworthiness</td><td>Level 1</td><td style="font-size:0.85em">[System] demonstrates trustworthiness through documented risk management and stakeholder engagement per [standard]‚Ä¶</td></tr>
          <tr><td><code>SC-Trustworthiness-002</code></td><td>Trustworthiness</td><td>Level 2</td><td style="font-size:0.85em">[System] achieves trustworthiness score ‚â• [threshold] across [N] evaluated characteristics per [standard]‚Ä¶</td></tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>

  <!-- DOC-20: ISO/IEC 38507 (2026-02-20 Ïã†Í∑ú) -->
  <div class="req-accordion" id="acc-TC-DOC-20" data-shall="2" data-should="89">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-20')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">20</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC 38507</span>
        <span class="badge badge-is">IS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Governance Implications of the Use of AI</span>
        <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 6px;margin-left:6px;font-size:0.75em">Accountability ‚¨Ü</span>
        <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 6px;margin-left:4px;font-size:0.75em">Risk ‚¨Ü</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 2</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 89</span>
        <span id="arrow-TC-DOC-20" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-20" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="display:flex;gap:8px;flex-wrap:wrap">
          <span style="background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:2px 8px;font-size:0.78em">Accountability</span>
          <span style="background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:2px 8px;font-size:0.78em">Risk ‚¨Ü</span>
          <span style="background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:2px 8px;font-size:0.78em">Transparency</span>
          <span style="background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:2px 8px;font-size:0.78em">Human Oversight</span>
        </div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (2)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">4.1</td>
              <td class="req-text">references to existing standards) that shall be followed, is given in Annex A. The governing body&#x27;s responsibility to set goals in traditional contexts extends to both financial objectives and non-financial outcomes including culture, values and ethical outcomes. Organizational and governance policies are generally created and enforced through a combination of controls, business plans, strategies, position descriptions, professional discipline accepted practice, regulation, training, key performance indicators and a variety of executive communications.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.3</td>
              <td class="req-text">However, the organization does not exist in isolation and therefore consideration shall be given to its stakeholders and the environment in which it operates. Consequences and likelihood of risks affecting stakeholders such as customers and suppliers should be key considerations in terms of risk to the organization.</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (89)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">4.1</td>
              <td class="req-text">The members of the governing body should assure themselves and be able to demonstrate to stakeholders that their policies (together with the implementation of those policies) are sufficient for the organization, its products and interactions, and the human resources, processes and technology the organization uses. In this respect, the responsibility for and resulting from the introduction of AI is not new. However, AI has the potential to enable new organizational objectives, and to fulfil or extend existing ones, and do so more effectively and more efficiently.</td>
            </tr>
            <tr>
              <td class="clause-col">4.2</td>
              <td class="req-text">when AI is being used within that organization. The specific choice of tools, e.g. AI systems, should be a management decision, made in light of and in line with guidance from the governing body. In order to establish such guidance, the governing body should inform itself about AI in general terms because its use can bring:</td>
            </tr>
            <tr>
              <td class="clause-col">4.2</td>
              <td class="req-text">establish such guidance, the governing body should inform itself about AI in general terms because its use can bring:</td>
            </tr>
            <tr>
              <td class="clause-col">4.2</td>
              <td class="req-text">The governing body should assess its intended use of AI as part of its risk appetite. Risk can change rapidly. New insights and a proactive approach provide an organization with the means to respond to risk. The organization should therefore demonstrate willingness to modify or abort projects, if deemed necessary. For further guidance see ISO/IEC 38506.</td>
            </tr>
            <tr>
              <td class="clause-col">4.2</td>
              <td class="req-text">risk. The organization should therefore demonstrate willingness to modify or abort projects, if deemed necessary. For further guidance see ISO/IEC 38506.</td>
            </tr>
            <tr>
              <td class="clause-col">4.2</td>
              <td class="req-text">The use of AI can also reduce or eliminate certain existing risks and the governing body should review and adjust its risk assessment accordingly.</td>
            </tr>
            <tr>
              <td class="clause-col">4.3</td>
              <td class="req-text">The governing body should take responsibility for the use of AI, rather than attributing responsibility to the AI system itself. Members of the governing body are responsible for informing themselves about the possibilities and risks raised by using AI systems. Members of the governing body should be conscious of the risk of anthropomorphising AI, a phenomenon by which human characteristics (e.g. thinking, emoting, judging, moralizing) are unduly attributed to AI systems, out of proportion, or in a manner inappropriate, to that which is necessary in order to understand the role played by the use of AI.</td>
            </tr>
            <tr>
              <td class="clause-col">4.3</td>
              <td class="req-text">possibilities and risks raised by using AI systems. Members of the governing body should be conscious of the risk of anthropomorphising AI, a phenomenon by which human characteristics (e.g. thinking, emoting, judging, moralizing) are unduly attributed to AI systems, out of proportion, or in a manner inappropriate, to that which is necessary in order to understand the role played by the use of AI.</td>
            </tr>
            <tr>
              <td class="clause-col">4.3</td>
              <td class="req-text">The governing body therefore should ensure that its practices are fit-for-purpose for the specific uses to which AI is being applied within the organization. This can include review and, where necessary, enhancement of:</td>
            </tr>
            <tr>
              <td class="clause-col">4.3</td>
              <td class="req-text">The governing body should also ensure that it has sufficient capabilities to deal with the implications of the use of AI. Actions to address this can include:</td>
            </tr>
            <tr>
              <td class="clause-col">4.3</td>
              <td class="req-text">The governing body&#x27;s accountability should be established across all aspects of intended or actual use of AI and in a manner that is sufficient to ensure the intended outcomes, notably:</td>
            </tr>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">As such, the governing body should understand what the &quot;use of AI&quot; entails and at what stage in its use the governing body should be involved either directly or through appropriate governance mechanisms.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">the governing body should be involved either directly or through appropriate governance mechanisms. AI systems build on existing IT capabilities including networking, Internet of things devices, e.g. sensors and actuators, big data and cloud computing.</td>
            </tr>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">AI should be included in the organization&#x27;s risk assessment. The use of AI can result in new obligations for the organization. These can be legal requirements or as a consequence of the adoption of voluntary codes of practice, whether directly within an AI system&#x27;s automation of decision-making processes or indirectly through its use of data or other resources or processes. The potential for an AI system to cross the boundary between presenting options for action and executing the action itself, without a human involved, should be a major consideration for the</td>
            </tr>
            <tr>
              <td class="clause-col">5.1</td>
              <td class="req-text">and executing the action itself, without a human involved, should be a major consideration for the governing body.</td>
            </tr>
            <tr>
              <td class="clause-col">5.2.3</td>
              <td class="req-text">‚Äî AI systems can inadvertently circumvent existing governance controls. Management should ensure that AI systems explicitly comply with existing governance controls.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">components in this ecosystem become a functional part of the overall AI system and should be treated as such from a governance perspective.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3</td>
              <td class="req-text">organizational considerations that should be factored during the entire life cycle.</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">opportunities against risk and other implications of use. It should ensure that oversight mechanisms exist and are used to review whether the deployment remains consistent with the organization&#x27;s strategic intent, purpose and values. AI can be used to fulfil objectives and create value for the organization. This can result in</td>
            </tr>
            <tr>
              <td class="clause-col">5.4</td>
              <td class="req-text">way, AI technologies can bring profound transformation to organizations. The governing body should learn about the opportunities that AI presents for the organization and promote its adoption when appropriate.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">While the organization can easily identify the benefits of the use of AI, the governing body should understand the constraints and obligations that such use places on the organization. To adequately govern these constraints and obligations, the organization should take some of the following actions:</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">govern these constraints and obligations, the organization should take some of the following actions:</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">should ensure that the requisite authority, responsibility and accountability are maintained and that the consequences of such automation are examined and understood before implementation.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">stakeholders (e.g. refusing a bank loan to a customer), the organization should ensure that such impacts are not exacerbated by the use of AI. Existing risk and impact assessments, together with</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">mitigation processes, e.g. those preserving legal rights or ensuring legal certainty, should remain effective (see 6.7).</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">will be challenged and can be the subject of new legal requirements. The governing body should show how such obligations are met and that they are in line with requirements and suitably explained if required.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">reduce costs), but overall, the use of AI should assist the organization in reaching its objectives.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">should take into account organizational policies, expectations (including impact of use) and ethics.</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">if it decides to use AI, together with measures to treat these risks, the organization should remain within the bounds of its risk appetite (see 6.7).</td>
            </tr>
            <tr>
              <td class="clause-col">5.5</td>
              <td class="req-text">governing body should also seek assurance from management that such constraints are adequately managed.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">The governing body and managers should further involve stakeholders that can be impacted by the use of AI systems, such as personnel and their representatives, throughout the entire process of implementing AI systems at organisations, via information, consultation and participation procedures.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">should consider in order to reduce the occurrence of avoidable and unintended consequences of the organization&#x27;s use of AI. It is not and cannot be comprehensive.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">Regardless of the use of any technology, the governing body should set and oversee the achievement of outcomes that are aligned to its principles. Such principles can arise internally or be suggested or imposed by external organizations (e.g. in[18],[19],[20] and[21]).</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">The speed of technological innovation and ever-changing legal requirements should encourage the organization to actively maintain a set of principles for its use of AI and ensure that they remain appropriate for the organization&#x27;s use of AI.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">The governing body should ensure that oversight arrangements for AI are established and are appropriate to the risks associated with the organization&#x27;s use of AI.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">Governance oversight, based on policies set by an organization, should identify the individual and the collective accountability in a chain of responsibility. Good governance oversight should be based on the</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">collective accountability in a chain of responsibility. Good governance oversight should be based on the</td>
            </tr>
            <tr>
              <td class="clause-col">6.2</td>
              <td class="req-text">As part of its governance oversight of AI, a governing body should ensure that:</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">The governing body should monitor the types of decision and output generated by automated systems and direct management to ensure that such systems are configured to operate within acceptable bounds by implementing appropriate controls. Such controls should provide the governing body with appropriate visibility of the conformance of decision-making to organizational policies, together with any exceptions thereto.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">bounds by implementing appropriate controls. Such controls should provide the governing body with appropriate visibility of the conformance of decision-making to organizational policies, together with any exceptions thereto.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">The governing body should seek assurance that active oversight of such controls is delegated to an appropriately resourced member of staff who has the authority to make or instigate responses to issues identified. The use of automated decision-making, delivered by an AI system, does not alter the accountability of the governing body (nor the responsibilities of any delegated authority) for such decisions.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">‚Äî Alignment to objectives. Decisions should align to the organizational objectives while keeping within the allocated resources, defined risk and other controls imposed by the organization.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">accountability for the actions and decisions performed by an AI system should be clearly defined 2) Under preparation. Stage at the time of publication: ISO/IEC DIS 23894.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">‚Äî Decision-making capability. Decision-makers should be adequately skilled and trained for the decisions for which they are responsible. Controls should be implemented to ensure AI systems are adequate to the task they have been set. See ISO/IEC TR 24028.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">decisions for which they are responsible. Controls should be implemented to ensure AI systems are adequate to the task they have been set. See ISO/IEC TR 24028.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">‚Äî Decision-making oversight . The governing body should ensure that there is adequate oversight, that controls are implemented to ensure effective decision-making capabilities and that there is appropriate visibility of both conformity of decision-making to organizational policies and any exceptions. For conformity exceptions in decision making, the need for additional transparency and accountability should be determined. Appropriate means should be given to all stakeholders to identify and report non-compliant behaviour, or decision-making outcomes generally (whether or</td>
            </tr>
            <tr>
              <td class="clause-col">6.3</td>
              <td class="req-text">and accountability should be determined. Appropriate means should be given to all stakeholders to identify and report non-compliant behaviour, or decision-making outcomes generally (whether or not they include AI systems) and be given meaningful, timely and adequate response.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">to the responsible use of AI. The governing body should ensure at an early stage that existing governance and management are adequate for the purpose for which that data are being used and that sensitive data are protected and secured (see ISO/IEC 38505-1). This includes, for example, documenting how the organization complies with its obligations including in regard to procurement and sale, privacy and security, retention and disposal of data as well as overseeing its own policies regarding data management (see also 6.7.4).</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">the governing body should seek assurance from management that data are of requisite quality for its intended use in AI systems.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">Existing governance of the use of data and data management practices should be reviewed where data are used in AI systems. In addition, for shared AI systems such as for industry analysis, additional governance policy and management controls can be required.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">The organization should consider applying the provisions of ISO/IEC 38505-1, relating to the use of data, to these aspects of governance of the use of AI:</td>
            </tr>
            <tr>
              <td class="clause-col">6.4</td>
              <td class="req-text">outlined in ISO/IEC 38505-1, governing bodies should take actions that ensure the effective governance of, and investment in, the organization&#x27;s use of data, and treat risks involved in that use. This includes ensuring that the correct data are being used for the correct purpose.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">operations and impact. Governing bodies should be aware of emerging guidance and international norms of behaviour such as those reflected in the Universal Declaration of Human Rights,[22] the Johannesburg Declaration on Sustainable Development [23] and other instruments. Further details can be found in ISO 26000:2010, 3.3.2.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">Any decision or action of the organization should align with its culture and values. However, much of an organization&#x27;s culture and values are implicitly embedded in the behaviour of its staff and processes.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">For these reasons, the governing body should be explicit about its culture and values and have the appropriate governance mechanisms and policies to ensure such AI system behaviours can be monitored and corrected when needed. In some cases, the scope and impact of the AI system should be constrained, and augmented by human action, so that governance policies can be ensured. How that is achieved will vary according to circumstances. Equally, an AI system can help identify where human decision-making is flawed (e.g. by inappropriate bias or discrimination, or by poor reasoning</td>
            </tr>
            <tr>
              <td class="clause-col">6.5</td>
              <td class="req-text">monitored and corrected when needed. In some cases, the scope and impact of the AI system should be constrained, and augmented by human action, so that governance policies can be ensured. How that is achieved will vary according to circumstances. Equally, an AI system can help identify where human decision-making is flawed (e.g. by inappropriate bias or discrimination, or by poor reasoning</td>
            </tr>
            <tr>
              <td class="clause-col">6.6.1</td>
              <td class="req-text">The governing body should seek assurances that management configures and maintains any AI system used by the organization to meet the organization&#x27;s compliance obligations and avoid breaches of compliance. Examples of breaches include pricing mechanisms that violate anti-trust legal requirements or the use of data for training that violates civil rights or is discriminatory.</td>
            </tr>
            <tr>
              <td class="clause-col">6.6.1</td>
              <td class="req-text">governing body should address these items:</td>
            </tr>
            <tr>
              <td class="clause-col">6.6.1</td>
              <td class="req-text">of an AI system that can lead staff to assume that it is error-free. The organization should establish appropriate processes to validate the output of an AI system;</td>
            </tr>
            <tr>
              <td class="clause-col">6.6.1</td>
              <td class="req-text">‚Äî the existing compliance management system should be assessed against the implications posed by the use of AI (where for example, designs and solutions can be difficult to explain and be subject to frequent changes), which can include, e.g. extending the compliance policy, or expanding the periodic risk assessment;</td>
            </tr>
            <tr>
              <td class="clause-col">6.6.2</td>
              <td class="req-text">At the compliance management level, particular attention should be paid to:</td>
            </tr>
            <tr>
              <td class="clause-col">6.6.2</td>
              <td class="req-text">The organization should assess the impact of any planned use of AI using the compliance management system. Possible uses of AI within the management system should be part of this evaluation.</td>
            </tr>
            <tr>
              <td class="clause-col">6.6.2</td>
              <td class="req-text">system. Possible uses of AI within the management system should be part of this evaluation.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.1</td>
              <td class="req-text">‚Äî ISO/IEC 23894:‚Äî, which describes the management processes that should be performed within the organization to address the additional risks to the organization through the introduction of an AI system.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.1</td>
              <td class="req-text">A review of current risk management processes should particularly examine whether the risks involved in decision-making, data use, culture and values, and compliance are well understood and managed. In this way, the context of the additional risks that AI systems bring to the organization can be clarified.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.2</td>
              <td class="req-text">data, and to the organization&#x27;s desired culture and values should be revised to take account of possible impacts of the use of AI.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.2</td>
              <td class="req-text">In order to address the risks posed by AI, the governing body should put in place:</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.2</td>
              <td class="req-text">In addition, the governing body should ensure that the organization&#x27;s contractors and sub-contractors abide by the same codes of practice and policies.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.2</td>
              <td class="req-text">a lead contractor or procurer. The organization should acquire a clear understanding of the implications of the use of AI within contractual relationships where the risk appetites of different organizations are in play.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.3</td>
              <td class="req-text">‚Äî Accountability and Responsibility. The governing body should maintain its accountability as well as oversight of the organization&#x27;s responsibilities both internally and externally for the use of AI.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.3</td>
              <td class="req-text">affecting stakeholders such as customers and suppliers should be key considerations in terms of risk to the organization.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.3</td>
              <td class="req-text">In situations where there is a significant risk to the duty of care, the governing body should require additional organizational controls to effectively treat such risks and ensure they do not exceed the risk appetite of the organization (see 6.7. 5 for examples).</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.3</td>
              <td class="req-text">the organization should be especially alert to the nature and consequences of that harm. Where necessary, the organization should put in place appropriate systems for the ongoing management of safety as well as considering how the use of AI can reduce the exposure of humans to dangerous activities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.3</td>
              <td class="req-text">necessary, the organization should put in place appropriate systems for the ongoing management of safety as well as considering how the use of AI can reduce the exposure of humans to dangerous activities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.3</td>
              <td class="req-text">‚Äî Security and Privacy. The organization should ensure the security of its operations, especially where confidentiality is necessary and the privacy of individuals is important. These objectives should not be altered by the use of AI, particularly given the ability of AI systems to infer new information from patterns in data.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.3</td>
              <td class="req-text">should not be altered by the use of AI, particularly given the ability of AI systems to infer new information from patterns in data.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.3</td>
              <td class="req-text">‚Äî Data. Data are an important resource for the organization and its protection and integrity should be an organizational objective.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.4</td>
              <td class="req-text">The organization should expect additional sources of risk depending on the scope and nature of the domain to which an AI system is applied and the type of AI system deployed. Some uses of AI will be contained and controlled, bringing little, or no additional risk to an organization. Other uses will carry significant exposures that have not previously been present in the organization.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.4</td>
              <td class="req-text">can also apply to many other technologies or processes. The organization should expect additional sources of risk depending on the scope and nature of the AI systems used. The examples shown include:</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.4</td>
              <td class="req-text">appropriateness of the data are critical and should be aligned with the intended use and objectives of the system. Manipulated data can permit an adversarial attack resulting in model poisoning and misclassifications.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.4</td>
              <td class="req-text">‚Äî Contractual issues. The governing body should ensure that applicable contracts, laws and best practices remain valid when AI systems are used. In many AI applications, systems learn from the data and practice of their host organization, in an initial, and potentially ongoing, basis. This uniquely makes AI systems reflective of the organization they serve in a way that can affect the applicability of contracts, laws and best practices.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.4</td>
              <td class="req-text">‚Äî Environmental issues . The governing body should consider the risk of carbon emissions resulting from energy consumption for AI training and data processing. It should also consider the risk of pollution and resource depletion due to accelerated obsolescence of hardware in favour of newer AI-capable cloud and edge devices.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.4</td>
              <td class="req-text">from energy consumption for AI training and data processing. It should also consider the risk of pollution and resource depletion due to accelerated obsolescence of hardware in favour of newer AI-capable cloud and edge devices.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.4</td>
              <td class="req-text">should consider the impact of the use of AI on the autonomy of humans, as individuals and as communities.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.5</td>
              <td class="req-text">should be transparent enough to ensure its applicability to the intended use.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.5</td>
              <td class="req-text">‚Äî Education and training. Everyone involved in all stages of the use of AI should receive adequate training to ensure that they acquire and deploy the requisite skills.</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.5</td>
              <td class="req-text">and policies that set the direction for investments in IT and what IT should achieve. They should encourage a culture of good governance of IT in their organization and direct the submission of proposals for approval to address identified needs (see Figure A.1).</td>
            </tr>
            <tr>
              <td class="clause-col">6.7.5</td>
              <td class="req-text">ISO 37000:2021, 6.4.1 states that the governing body should oversee the organization&#x27;s performance to ensure that it meets the governing body&#x27;s intentions for, and expectations of, the organization, its ethical behaviour and its compliance obligations.</td>
            </tr>
            <tr>
              <td class="clause-col">General</td>
              <td class="req-text">governing body should understand the risks of data and how to direct managers to manage these risks. The risks not only manifest themselves in data breaches, but also in the misuse of data and any reputational risks that arise therefrom.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
    </div>
  </div>

  <!-- DOC-21: ISO/IEC TS 4213 (2026-02-20 Ïã†Í∑ú) -->
  <div class="req-accordion" id="acc-TC-DOC-21" data-shall="8" data-should="19">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-21')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">21</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC TS 4213</span>
        <span class="badge badge-ts">TS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Assessment of Machine Learning Classification Performance</span>
        <span style="display:inline-block;background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:1px 6px;margin-left:6px;font-size:0.75em">Quality ‚¨Ü TC-QUAL-005/006</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 8</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 19</span>
        <span id="arrow-TC-DOC-21" style="font-size:0.7em;color:#888;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-21" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="display:flex;gap:8px;flex-wrap:wrap">
          <span style="background:#e8f5e9;color:#2d6a4f;border:1px solid #a5d6a7;border-radius:10px;padding:2px 8px;font-size:0.78em">Quality ‚¨Ü (TC-QUAL-005/006)</span>
          <span style="background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:2px 8px;font-size:0.78em">Functional Correctness</span>
          <span style="background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:2px 8px;font-size:0.78em">Fairness</span>
          <span style="background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:2px 8px;font-size:0.78em">Transparency</span>
        </div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (8)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.3.5</td>
              <td class="req-text">The data used to test a machine learning model shall be the same for all machine learning models being compared.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.5</td>
              <td class="req-text">The test and validation data shall contain no samples that overlap with training data.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.10</td>
              <td class="req-text">No information from the test set shall be used when adjusting hyperparameters, as this typically leads to over-optimistic performance estimation.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.11</td>
              <td class="req-text">The evaluation environment shall not be modified while the assessment is in progress; hardware and system software shall not be modified during the assessment.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.12</td>
              <td class="req-text">Any use of acceleration during training or testing shall be reported.</td>
            </tr>
            <tr>
              <td class="clause-col">6.4.3</td>
              <td class="req-text">A basis for selection of the appropriate multi-class performance approach shall be reported.</td>
            </tr>
            <tr>
              <td class="clause-col">6.5.1</td>
              <td class="req-text">A basis for selection of the metric for multi-label performance assessment shall be reported.</td>
            </tr>
            <tr>
              <td class="clause-col">7.1</td>
              <td class="req-text">This accounting shall include the number of samples available for evaluation and the distribution of samples.</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (19)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="clause-col">5.3.1</td>
              <td class="req-text">When assessing machine learning classification performance, consistent approaches and methods should be applied to demonstrate relevance, legitimacy and extensibility.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.2</td>
              <td class="req-text">Except when done for specific goal-relevant reasons, the training and test data should be as free of sampling bias as possible.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.2</td>
              <td class="req-text">The data used to test a machine learning model should be representative of the intended use of the system.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.2</td>
              <td class="req-text">Extra care should be taken when splitting unbalanced data into training and test to ensure that similar distributions are maintained.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.3</td>
              <td class="req-text">In particular, when pre-processing favours one model over another, their performance gap should not be attributed to the downstream algorithms.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.4</td>
              <td class="req-text">In particular, in such cases any performance gap should be attributed to the combination of the algorithm and training data, rather than to just the algorithm.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.7</td>
              <td class="req-text">Evaluations should be designed to prevent information leakage between training and test data.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.8</td>
              <td class="req-text">The data should be as free of channel effects as possible.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.8</td>
              <td class="req-text">Reporting should describe known channel effects introduced to the training data.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.9</td>
              <td class="req-text">When assessing classification performance, a strong generalizable ground truth should be established.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.10</td>
              <td class="req-text">Hyperparameter types should be reported for all machine learning algorithms in an assessment, as well as hyperparameter values for each machine learning model.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.11</td>
              <td class="req-text">The evaluation environment should meet the minimum environmental requirements required by the machine learning models under assessment.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.12</td>
              <td class="req-text">The same test environment should be used for all machine learning models under evaluation.</td>
            </tr>
            <tr>
              <td class="clause-col">6.2.3</td>
              <td class="req-text">Accuracy should not be used to express comparative performance across models unless classes are known to be reasonably balanced.</td>
            </tr>
            <tr>
              <td class="clause-col">8</td>
              <td class="req-text">In addition to normative elements elsewhere in this document, the following should be reported: source, size and composition of training data; source, size and composition of test data; efforts taken to analyse, account for and reduce bias in test and training data.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.6</td>
              <td class="req-text">When new models are evaluated that can operate on different data representations, the models should be compared by using the same input data representation.</td>
            </tr>
            <tr>
              <td class="clause-col">5.3.7</td>
              <td class="req-text">Where possible, an evaluation campaign should use training data with only the minimum amount of information necessary to train the model.</td>
            </tr>
            <tr>
              <td class="clause-col">6.1</td>
              <td class="req-text">A summary of the metrics recommended and the use cases for which they are recommended should be provided.</td>
            </tr>
            <tr>
              <td class="clause-col">6.3.2</td>
              <td class="req-text">For binary classification, the following performance metrics and associated measures should be used as the basis for assessing the classification performance.</td>
            </tr>
          </tbody>
        </table>
      </div>
      </div>
    </div>
  </div>
    <div class="req-accordion" id="acc-TC-DOC-22" data-shall="0" data-should="0">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-22')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">22</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC DTR 20226</span>
        <span class="badge badge-dtr">DTR</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Environmental Sustainability of AI Systems</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 0</span>
        <span id="arrow-TC-DOC-22" style="font-size:1em;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-22" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f5e9;color:#1e8449;border:1px solid #a9dfbf;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Efficiency</span><span style="display:inline-block;background:#fef9e7;color:#b7950b;border:1px solid #f7dc6f;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Trustworthiness</span></div>
      <div style="background:#fff3cd;border:1px solid #ffc107;border-radius:4px;padding:8px 10px;margin-top:8px;font-size:0.82em">
        <strong>Note:</strong> ISO/IEC DTR 20226 is a Draft Technical Report (informative). It provides an overview of environmental sustainability aspects of AI systems including energy consumption, carbon impact, water usage, e-waste, and supply chain. As a TR, it contains no normative SHALL/SHOULD requirements.
      </div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHOULD statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      </div>
    </div>
    </div>
    <div class="req-accordion" id="acc-TC-DOC-23" data-shall="0" data-should="0">
    <div class="req-acc-header" onclick="toggleAcc('TC-DOC-23')">
      <span style="display:inline-flex;align-items:center;justify-content:center;background:#2c3e50;color:white;width:24px;height:24px;border-radius:50%;font-size:0.72em;font-weight:700;flex-shrink:0">23</span>
      <div style="flex:1;min-width:0">
        <span style="font-family:monospace;font-weight:700;color:#1a4480;margin-right:6px;font-size:0.88em">ISO/IEC FDIS 12792</span>
        <span class="badge badge-fdis">FDIS</span>
        <span style="color:#333;font-size:0.85em;margin-left:4px">Transparency Taxonomy of AI Systems</span>
      </div>
      <div style="display:flex;align-items:center;gap:6px;flex-shrink:0">
        <span style="background:#fde8e8;color:#c0392b;border:1px solid #f5b7b1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHALL: 0</span>
        <span style="background:#d6eaf8;color:#2471a3;border:1px solid #aed6f1;padding:1px 10px;border-radius:10px;font-size:0.76em;font-weight:600">SHOULD: 0</span>
        <span id="arrow-TC-DOC-23" style="font-size:1em;transition:transform 0.2s">‚ñ∂</span>
      </div>
    </div>
    <div class="req-acc-body" id="body-TC-DOC-23" style="display:none">
      <div style="background:#f8f9fa;border-radius:6px;padding:10px 14px;margin-bottom:14px">
      <div style="font-size:0.83em"><strong>Related Characteristics:</strong> <span style="display:inline-block;background:#e8f4fd;color:#2471a3;border:1px solid #aed6f1;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Transparency</span><span style="display:inline-block;background:#f0e6ff;color:#6c3483;border:1px solid #d2b4de;border-radius:10px;padding:1px 8px;margin:2px;font-size:0.8em">Explainability</span></div>
      <div style="background:#fff3cd;border:1px solid #ffc107;border-radius:4px;padding:8px 10px;margin-top:8px;font-size:0.82em">
        <strong>Note:</strong> ISO/IEC FDIS 12792 specifies a taxonomy of information elements for AI transparency, covering 4 levels: Context-level, System-level, Model-level, and Dataset-level. As a taxonomy/classification standard, it defines WHAT to disclose rather than HOW (no normative SHALL/SHOULD requirements in body text).
      </div>
      <div class="req-type-section">
        <h4 style="color:#c0392b;margin:0 0 10px">SHALL ‚Äî Mandatory Requirements (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#fdf2f2;border-bottom:2px solid #c0392b">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Requirement Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHALL statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      <div class="req-type-section">
        <h4 style="color:#2471a3;margin:0 0 10px">SHOULD ‚Äî Recommendations (0)</h4>
        <table style="width:100%;border-collapse:collapse">
          <thead>
            <tr style="background:#f0f4f8;border-bottom:2px solid #2471a3">
              <th class="clause-col" style="padding:6px 8px;text-align:left">Clause</th>
              <th style="padding:6px 8px;text-align:left;font-size:0.87em">Recommendation Text</th>
            </tr>
          </thead>
          <tbody>
            <tr><td colspan="2" style="color:#888;font-style:italic;padding:10px 8px">No SHOULD statements identified in normative content.</td></tr>
          </tbody>
        </table>
      </div>
      </div>
    </div>
    </div>
</div>
<script>
function toggleAcc(id){var b=document.getElementById('body-'+id),a=document.getElementById('arrow-'+id);if(b.style.display==='none'){b.style.display='block';a.style.transform='rotate(90deg)';}else{b.style.display='none';a.style.transform='';}}
function expandAll(){document.querySelectorAll('.req-acc-body').forEach(function(b){b.style.display='block';});document.querySelectorAll('[id^="arrow-"]').forEach(function(a){a.style.transform='rotate(90deg)';}); }
function collapseAll(){document.querySelectorAll('.req-acc-body').forEach(function(b){b.style.display='none';});document.querySelectorAll('[id^="arrow-"]').forEach(function(a){a.style.transform='';}); }
function filterDocs(type,btn){document.querySelectorAll('.filter-btn').forEach(function(b){b.classList.remove('active');});btn.classList.add('active');document.querySelectorAll('.req-accordion').forEach(function(acc){var shall=parseInt(acc.dataset.shall||0),should=parseInt(acc.dataset.should||0);if(type==='all')acc.style.display='';else if(type==='has-shall')acc.style.display=shall>0?'':'none';else if(type==='has-should')acc.style.display=should>0?'':'none';});}
</script>
</body>
</html>